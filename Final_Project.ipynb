{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Project Notebook**"
      ],
      "metadata": {
        "id": "GGwTiINKWiLs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFNRiQb4R3WP"
      },
      "source": [
        "## **Setup & Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "BsBQ9VbffXlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8e4797-a5ec-4d66-8519-34074611fd5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.57.3\n",
            "Uninstalling transformers-4.57.3:\n",
            "  Successfully uninstalled transformers-4.57.3\n",
            "Found existing installation: torch 2.9.0+cu126\n",
            "Uninstalling torch-2.9.0+cu126:\n",
            "  Successfully uninstalled torch-2.9.0+cu126\n",
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Found existing installation: torchvision 0.24.0+cu126\n",
            "Uninstalling torchvision-0.24.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.24.0+cu126\n",
            "Found existing installation: wandb 0.23.1\n",
            "Uninstalling wandb-0.23.1:\n",
            "  Successfully uninstalled wandb-0.23.1\n",
            "Collecting llmcompressor\n",
            "  Downloading llmcompressor-0.8.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting loguru<=0.7.3,>=0.7.2 (from llmcompressor)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pyyaml<=6.0.3,>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (6.0.3)\n",
            "Requirement already satisfied: numpy<=2.3.3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (2.0.2)\n",
            "Requirement already satisfied: requests<=2.32.5,>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (2.32.4)\n",
            "Requirement already satisfied: tqdm<=4.67.1,>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (4.67.1)\n",
            "Collecting torch<=2.8.0,>=2.7.0 (from llmcompressor)\n",
            "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting transformers<=4.56.2,>=4.53.0 (from llmcompressor)\n",
            "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets<=4.1.1,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (4.0.0)\n",
            "Collecting accelerate<=1.10.1,>=1.6.0 (from llmcompressor)\n",
            "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting nvidia-ml-py<=13.580.82,>=12.560.30 (from llmcompressor)\n",
            "  Downloading nvidia_ml_py-13.580.82-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: pillow<=11.3.0,>=10.4.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (11.3.0)\n",
            "Collecting compressed-tensors==0.12.2 (from llmcompressor)\n",
            "  Downloading compressed_tensors-0.12.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.12.2->llmcompressor) (2.12.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (5.9.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (2025.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch<=2.8.0,>=2.7.0->llmcompressor)\n",
            "  Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.56.2,>=4.53.0->llmcompressor) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.56.2,>=4.53.0->llmcompressor) (0.22.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate<=1.10.1,>=1.6.0->llmcompressor) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor) (0.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<=2.8.0,>=2.7.0->llmcompressor) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<=2.8.0,>=2.7.0->llmcompressor) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.17.0)\n",
            "Downloading llmcompressor-0.8.1-py3-none-any.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.2/273.2 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.12.2-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-13.580.82-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.0/49.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-ml-py, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, loguru, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, transformers, torch, compressed-tensors, accelerate, llmcompressor\n",
            "  Attempting uninstall: nvidia-ml-py\n",
            "    Found existing installation: nvidia-ml-py 13.590.44\n",
            "    Uninstalling nvidia-ml-py-13.590.44:\n",
            "      Successfully uninstalled nvidia-ml-py-13.590.44\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.12.0\n",
            "    Uninstalling accelerate-1.12.0:\n",
            "      Successfully uninstalled accelerate-1.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.8.5 requires torchvision>=0.11, which is not installed.\n",
            "timm 1.0.22 requires torchvision, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-1.10.1 compressed-tensors-0.12.2 llmcompressor-0.8.1 loguru-0.7.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-ml-py-13.580.82 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 torch-2.8.0 transformers-4.56.2 triton-3.4.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing device: cuda\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall transformers torch torchaudio torchvision wandb -y\n",
        "!pip install llmcompressor\n",
        "!pip install -q accelerate bitsandbytes datasets scipy matplotlib wandb\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from datasets import Dataset\n",
        "import copy\n",
        "import gc\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import wandb\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E8tJpydOUJBM"
      },
      "outputs": [],
      "source": [
        "# Set for reproducibility\n",
        "import random\n",
        "import numpy as np\n",
        "from transformers import set_seed\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "set_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZfycqbNSRtx"
      },
      "source": [
        "## **Configuration & Experiment Controls**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-604U8KmSktc"
      },
      "outputs": [],
      "source": [
        "# --- Experiment Settings ---\n",
        "TEST_RUN = True\n",
        "if TEST_RUN:\n",
        "  MODELS_TO_TEST = [\"Qwen/Qwen2.5-0.5B-Instruct\"]\n",
        "  SENSITIVITY_THRESHOLDS = [0.0, 0.05]\n",
        "  CALIBRATION_SAMPLES = 128\n",
        "  EVAL_SAMPLES = 200\n",
        "  ENABLE_FP8_COMPARISON = False\n",
        "  ENABLE_BLOCK_WISE = False\n",
        "  WANDB_PROJECT_NAME = \"Test_Run\"\n",
        "else:\n",
        "  MODELS_TO_TEST = [\"Qwen/Qwen2.5-1.5B-Instruct\", \"Qwen/Qwen2.5-3B-Instruct\", \"Qwen/Qwen2.5-7B-Instruct\"]\n",
        "  SENSITIVITY_THRESHOLDS = [0.0, 0.01, 0.05, 0.10, 0.20]\n",
        "  CALIBRATION_SAMPLES = 128\n",
        "  EVAL_SAMPLES = 200 # Keep small for fast iteration, increase for final paper\n",
        "  ENABLE_FP8_COMPARISON = True\n",
        "  ENABLE_BLOCK_WISE = True\n",
        "  WANDB_PROJECT_NAME = \"KLD_Quantization_Project\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJwJlfxzTLc8"
      },
      "source": [
        "## **Metrics & Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- Quantization Helpers ---\n",
        "# def fake_quantize_tensor_rtn(w, bits=4):\n",
        "#     \"\"\"Simulate Round-to-Nearest Quantization\"\"\"\n",
        "#     max_val = w.abs().max()\n",
        "#     scale = max_val / (2**(bits-1) - 1)\n",
        "#     return (w / scale).round().clamp(-8, 7) * scale\n",
        "\n",
        "def recursive_getattr(obj, attr):\n",
        "    for part in attr.split('.'):\n",
        "        obj = getattr(obj, part)\n",
        "    return obj\n",
        "\n",
        "def recursive_setattr(obj, attr, val):\n",
        "    pre, _, post = attr.rpartition('.')\n",
        "    parent = recursive_getattr(obj, pre) if pre else obj\n",
        "    setattr(parent, post, val)"
      ],
      "metadata": {
        "id": "kblNy4pDduu8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CtOjgOt3TSXL"
      },
      "outputs": [],
      "source": [
        "# --- Metrics Helpers ---\n",
        "def compute_kld(logits_p, logits_q):\n",
        "    p_probs = F.softmax(logits_p, dim=-1)\n",
        "    q_log_probs = F.log_softmax(logits_q, dim=-1)\n",
        "    return nn.KLDivLoss(reduction='batchmean')(q_log_probs, p_probs).item()\n",
        "\n",
        "def calculate_flip_rate(base_preds, new_preds):\n",
        "    \"\"\"Calculates % of answers that changed from the baseline.\"\"\"\n",
        "    if not base_preds or not new_preds: return 0.0\n",
        "    flips = sum([1 for b, n in zip(base_preds, new_preds) if b != n])\n",
        "    return flips / len(base_preds)\n",
        "\n",
        "def compute_perplexity(model, tokenizer):\n",
        "    \"\"\"Computes perplexity on a subset of WikiText-2\"\"\"\n",
        "    encodings = tokenizer(\"\\n\\n\".join(load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")[\"text\"][:20]), return_tensors=\"pt\")\n",
        "    max_length = model.config.max_position_embeddings\n",
        "    stride = 512\n",
        "    seq_len = encodings.input_ids.size(1)\n",
        "\n",
        "    nlls = []\n",
        "    prev_end_loc = 0\n",
        "    for begin_loc in tqdm(range(0, seq_len, stride), desc=\"Computing PPL\"):\n",
        "        end_loc = min(begin_loc + max_length, seq_len)\n",
        "        trg_len = end_loc - prev_end_loc\n",
        "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
        "        target_ids = input_ids.clone()\n",
        "        target_ids[:, :-trg_len] = -100\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, labels=target_ids)\n",
        "            nlls.append(outputs.loss)\n",
        "\n",
        "        prev_end_loc = end_loc\n",
        "        if end_loc == seq_len: break\n",
        "\n",
        "    return torch.exp(torch.stack(nlls).mean()).item()\n",
        "\n",
        "def measure_efficiency(model, tokenizer, input_text=\"Hello world\"):\n",
        "    \"\"\"Measures Inference Latency and Peak VRAM Usage\"\"\"\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        # Generate 50 tokens to average out overhead\n",
        "        _ = model.generate(**input_ids, max_new_tokens=50, min_new_tokens=50)\n",
        "    end_time = time.time()\n",
        "\n",
        "    peak_mem = torch.cuda.max_memory_allocated() / 1024**3 # GB\n",
        "    latency = (end_time - start_time) # Seconds\n",
        "    return latency, peak_mem\n",
        "\n",
        "def evaluate_full_suite(model, tokenizer, dataset, metric_name):\n",
        "    \"\"\"Runs all metrics and returns them.\"\"\"\n",
        "    print(f\"--- Evaluating: {metric_name} ---\")\n",
        "\n",
        "    # 1. Accuracy\n",
        "    preds, truths = get_mmlu_predictions(model, dataset, EVAL_SAMPLES)\n",
        "    acc = sum([1 for p, g in zip(preds, truths) if p == g]) / len(truths)\n",
        "\n",
        "    # 2. Perplexity\n",
        "    ppl = compute_perplexity(model, tokenizer)\n",
        "\n",
        "    # 3. Efficiency\n",
        "    lat, mem = measure_efficiency(model, tokenizer)\n",
        "\n",
        "    print(f\"Results -> Acc: {acc:.2%}, PPL: {ppl:.2f}, Latency: {lat:.2f}s, Mem: {mem:.2f}GB\")\n",
        "    return acc, ppl, lat, mem, preds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MMLU Logic ---\n",
        "def format_mmlu_prompt(example):\n",
        "    options = [f\"{label}. {example['choices'][i]}\" for i, label in enumerate(['A', 'B', 'C', 'D'])]\n",
        "    prompt_text = f\"Question: {example['question']}\\nOptions:\\n\" + \"\\n\".join(options) + \"\\nAnswer:\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Output only the single letter (A, B, C, or D) corresponding to the correct answer.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_text}\n",
        "    ]\n",
        "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "def get_mmlu_predictions(model, dataset, num_samples):\n",
        "    predictions, ground_truths = [], []\n",
        "    choices = [\"A\", \"B\", \"C\", \"D\"]\n",
        "    choice_ids = [tokenizer.encode(c)[0] for c in choices]\n",
        "\n",
        "    for i in tqdm(range(min(num_samples, len(dataset))), desc=\"MMLU Eval\"):\n",
        "        ex = dataset[i]\n",
        "        inputs = tokenizer(format_mmlu_prompt(ex), return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits[0, -1, choice_ids]\n",
        "            pred = choices[torch.argmax(logits).item()]\n",
        "        predictions.append(pred)\n",
        "        ground_truths.append(choices[ex['answer']])\n",
        "    return predictions, ground_truths"
      ],
      "metadata": {
        "id": "_0TUVUuad1r0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2lOxztdUMfx"
      },
      "source": [
        "## **Advanced Sensitivity Profiling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_DZSQNF9UMGr"
      },
      "outputs": [],
      "source": [
        "def profile_restoration_sensitivity(model_q, model_ref, calib_input, granularity='layer'):\n",
        "    \"\"\"\n",
        "    Profiles sensitivity by measuring the KLD improvement when restoring\n",
        "    individual parts of the quantized model (model_q) back to FP16 (model_ref).\n",
        "\n",
        "    Returns:\n",
        "        sensitivity_scores: Dict mapping name -> KLD improvement (Higher is more sensitive).\n",
        "    \"\"\"\n",
        "    print(f\"Profiling Restoration Sensitivity (Granularity: {granularity})...\")\n",
        "\n",
        "    # Compute Baseline\n",
        "    model_ref.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        ref_device = next(model_ref.parameters()).device\n",
        "        base_logits = model_ref(calib_input.to(ref_device)).logits.to(device)\n",
        "        current_logits = model_q(calib_input.to(device)).logits\n",
        "        initial_kld = compute_kld(base_logits, current_logits)\n",
        "\n",
        "    print(f\"Initial Quantized KLD: {initial_kld:.6f}\")\n",
        "\n",
        "    sensitivity_scores = {}\n",
        "\n",
        "    def get_module_by_name(module, access_string):\n",
        "        names = access_string.split(sep='.')\n",
        "        return reduce(getattr, names, module)\n",
        "\n",
        "    from functools import reduce\n",
        "\n",
        "    # Block-wise or Layer-wise\n",
        "    if granularity == 'block':\n",
        "        if hasattr(model_q, 'model') and hasattr(model_q.model, 'layers'):\n",
        "            iterable_items = list(enumerate(model_q.model.layers))\n",
        "            prefix = \"model.model.layers\"\n",
        "        else:\n",
        "            raise ValueError(\"Could not detect transformer blocks structure.\")\n",
        "        iterator = tqdm(iterable_items, desc=\"Profiling Blocks\")\n",
        "    elif granularity == 'layer':\n",
        "        # # We limit this to just the linear layers to save time\n",
        "        # iterable_items = [(n, m) for n, m in model_q.named_modules() if isinstance(m, (nn.Linear,  import_bnb_linear_type_if_needed()))]\n",
        "        iterable_items = [(n, m) for n, m in model_q.named_modules()\n",
        "                          if \"mlp\" in n or \"self_attn\" in n]\n",
        "        iterator = tqdm(iterable_items, desc=\"Profiling Layers\")\n",
        "\n",
        "    # Restoration Loop\n",
        "    for name_or_idx, module_q in iterator:\n",
        "        target_name = f\"{prefix}.{name_or_idx}\" if granularity == 'block' else name_or_idx\n",
        "        try:\n",
        "            module_ref = recursive_getattr(model_ref, target_name)\n",
        "            backup_quant_module = recursive_getattr(model_q, target_name)\n",
        "            module_fp16_gpu = copy.deepcopy(module_ref).to(device)\n",
        "            recursive_setattr(model_q, target_name, module_fp16_gpu)\n",
        "\n",
        "            # Measure New KLD\n",
        "            with torch.no_grad():\n",
        "                new_logits = model_q(calib_input.to(device)).logits\n",
        "                new_kld = compute_kld(base_logits, new_logits)\n",
        "\n",
        "            improvement = initial_kld - new_kld\n",
        "            sensitivity_scores[target_name] = improvement\n",
        "            recursive_setattr(model_q, target_name, backup_quant_module)\n",
        "\n",
        "            # Cleanup VRAM\n",
        "            del module_fp16_gpu\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {target_name}: {e}\")\n",
        "\n",
        "    return sensitivity_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3uDgaguUZpM"
      },
      "source": [
        "## **The \"Surgery\" Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fez4Rpw3Ud04"
      },
      "outputs": [],
      "source": [
        "def perform_surgery(model, sensitive_names, fp16_model_cpu):\n",
        "    \"\"\"\n",
        "    Replaces the sensitive quantized layers in 'model' (GPU)\n",
        "    with the original FP16 layers from 'fp16_model_cpu' (CPU).\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    print(f\"Surgery: Replacing {len(sensitive_names)} Sensitive Layers with FP16...\")\n",
        "\n",
        "    for name in sensitive_names:\n",
        "        try:\n",
        "            # 1. Get original FP16 weight from CPU backup\n",
        "            original_layer = recursive_getattr(fp16_model_cpu, name)\n",
        "\n",
        "            # 2. Create new Linear layer on GPU\n",
        "            new_layer = nn.Linear(\n",
        "                in_features=original_layer.in_features,\n",
        "                out_features=original_layer.out_features,\n",
        "                bias=(original_layer.bias is not None)\n",
        "            )\n",
        "            new_layer.weight.data = original_layer.weight.data.to(model.device)\n",
        "            if original_layer.bias is not None:\n",
        "                new_layer.bias.data = original_layer.bias.data.to(model.device)\n",
        "\n",
        "            # 3. Swap into the quantized model\n",
        "            recursive_setattr(model, name, new_layer)\n",
        "            count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping layer {name}: {e}\")\n",
        "\n",
        "    print(f\"Surgery Complete: {count} layers restored.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_surgery(model, sensitive_names, fp16_model_cpu):\n",
        "    \"\"\"\n",
        "    Replaces the sensitive quantized layers in 'model' (GPU)\n",
        "    with the original FP16 layers from 'fp16_model_cpu' (CPU).\n",
        "\n",
        "    This Generic Version uses deepcopy, so it works for:\n",
        "    - Individual Linear layers (gate_proj, q_proj)\n",
        "    - Entire Blocks (Qwen2MLP, Qwen2Attention)\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    print(f\"Surgery: Replacing {len(sensitive_names)} Sensitive Layers with FP16...\")\n",
        "\n",
        "    for name in sensitive_names:\n",
        "        try:\n",
        "            # 1. Get original FP16 module from CPU backup\n",
        "            #    (This handles Linear, Qwen2MLP, Qwen2Attention, etc.)\n",
        "            original_module = recursive_getattr(fp16_model_cpu, name)\n",
        "\n",
        "            # 2. Create a deep copy and move to GPU\n",
        "            #    We use deepcopy instead of manually instantiating nn.Linear.\n",
        "            #    This preserves the exact class type and configuration.\n",
        "            module_fp16_gpu = copy.deepcopy(original_module).to(model.device)\n",
        "\n",
        "            # 3. Swap into the quantized model\n",
        "            recursive_setattr(model, name, module_fp16_gpu)\n",
        "\n",
        "            count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping layer {name}: {e}\")\n",
        "\n",
        "    print(f\"Surgery Complete: {count} layers restored.\")"
      ],
      "metadata": {
        "id": "3EBZbOuV2aJf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJUeRTUkUtkV"
      },
      "source": [
        "# Main Experiment Loop ( The Core )\n",
        "Goal: Run the full battery of tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "L8DT_16slQDF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710,
          "referenced_widgets": [
            "9f6a1d22bdd54f75a0470360565daa26",
            "4fb6b9d92dd046f69cc13e8992def2cd",
            "c5113a70acae4327ad31f53b186a0e5b",
            "bec5839fd7224fa6a747a151fe7e73f3",
            "c6c4600fec1f4ee9b6f65c8cbba90315",
            "18260c398ae2473db62188f4fbc6b12b",
            "cbc8a500c693486ebf24c9ac6417cb25",
            "2adbfb0d2f15459abd2612692cb9545c",
            "4955db1f4946430eaec6e03617741628",
            "3d3449ad04b0495191da22cb4a08af64",
            "513aa422f9a044cbb4e747aec80afcc3",
            "a0fb631df382456589d1b74837f6dc0b",
            "7375d9e08245474eb8228e06a2c86ed6",
            "729460a1cc9d4bd1b60ce828fc8f22eb",
            "3d358558a7cf413daafdd5ce8364f78d",
            "d08b54140abc44ea82a6f09ff8ac2b60",
            "d2838fad0bbc45968de578b3ef3141eb",
            "01a60a70601c4da1a88ec10b44c5afce",
            "be09d6fb532940b0a3fa0a0f6aa09725",
            "ddfc6d4894424dadb3f9ec83a97152be",
            "163aaf7689fe4eed816e463960eca75c",
            "989d05854ef34d0a98d2fca30bfa1221",
            "250fa64b855b4668bbb94c1bd2e55aba",
            "269cafa99234414fa0d9b68372eabc42",
            "52c7d96fd80242039309203b4f71db76",
            "2a2f7097322f412f895355c7cc81fd1f",
            "025c1070e8bc40ac9609ef3443a3c0c3",
            "f68645bd97164993947e136b20c8823e",
            "c18638b0c0004acda058d91ec004915e",
            "a217bec1e77c4dc287ea6fd3140c9a66",
            "eb5dea71b8284d42b0e977d904859c1c",
            "bd428a3539d545a59013ecc076b95811",
            "5effcc6158c74e99bf5301584353d97e",
            "71480db22206459ebe7e483e2be27471",
            "49cdc7f0359a47879375170013555f36",
            "acf9ede1181649ea843b6556d2a07b82",
            "b83b7c3ebb5245a1a8e5b474d574b53b",
            "ba1c1d1d5f3b4cae95414b3da8b7d146",
            "fa55ae4c1092482db1c32ccab9c9c25c",
            "ed101b991ff74d56b9d67185cda1bb52",
            "153cb404848749ada4ab195ea40a5dbc",
            "57e94a94e1fd4b62a49d43374aeea0f0",
            "4b2fd72f73154c27981fbf79f5b92025",
            "452368a0f9654acaafa36e1056f548a0",
            "93e0955d5a2848f680f30db73fff9775",
            "8401c4cb5a4643f58de3af1d2ec4c584",
            "2daaa8f942b244f0b9a68150e0e823d9",
            "66bddc3fd6cc4af994a858806c1488cc",
            "8bc34368480448bc82f5d8b0034e16fd",
            "8f4311d97b43416ba95a2b52dfc5913a",
            "85e0e5ff517249d1927fcbaa3c0f0b05",
            "94dec1e92d0348ec8fe9ae31068f1606",
            "d17b6f00b1b44d24af6315eaae00b1e1",
            "365a4e4a0611478f8b51179f32521caa",
            "028a1261e460416bb4de2d695da73b2e",
            "1315208aa6524b74acf38ef0bb666532",
            "781499f26ecc4596bc99ae66f2bfe7b0",
            "4da63f02b0164415946bbf49c13e97d0",
            "dea1380d55e14d71895b0819a6efdec0",
            "4b2f9c4d01c34f129b9cb9277e0ff74d",
            "e6e4695deb754d3b90958b14f20fd0dc",
            "cd96010d967442e7a3bfed924198cde3",
            "a8d35554c1944f0bbe0b8fa563ab382b",
            "ee17bcdc0d0e4f3e92d15c4291f30909",
            "9726e85c5f98439a911704bf1bce5699",
            "6d4e3599ffa04c8893283ba8cb8c8337",
            "f667567100654c48895ae28747bc3084",
            "fa2cd12a95564b1ab21b8762423dd592",
            "5c514f8a122e4fd88838e4bd2ac98456",
            "ff697d0610ff48028c2e871dc73e9a53",
            "fc263eba07b444c087b83689eff2025a",
            "0cf8d3a902a3418f85725fc581f40be8",
            "a98ef56855464be995cd85c5fdf7d1fd",
            "b9a81b90e9c34dd8a0d815a9840d53fd",
            "af4abd5c05ff43189ec60ab4ff7782d8",
            "01c9d7c11fd8417b8126c173733b7a65",
            "2de034682fdc4216a623122f905e90f3",
            "5dc6e5519db749f98ed15e74b42eff91",
            "493869e840bb41f08c3dc50701159893",
            "39c0105ad57e4f49b826dd3020a8179f",
            "f77d62e5af884680a0728b2a0216eb1b",
            "91770eca05294ccb93c681e4c865ea88",
            "12696b0c8df74f55adb60faf0e6a39ae",
            "7a8bc2c74e334dac94bf235fcd5c6507",
            "21143f7e6c7f47f2bf9649d3844b91d9",
            "26c2d5c8d0bd454f900bc3bd839dde84",
            "6fca2a34f9fd4580bd0bf16daf0a07e9",
            "132584fba34b4fb99cd500aa0bdfb7b7"
          ]
        },
        "outputId": "2b83634e-a07d-4ae1-dc22-cc1d63779196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 18966ec6a4104cefd2f27c1073a501de1c06951f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Invalid choice\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjd4123\u001b[0m (\u001b[33myq171014-columbia-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MMLU Dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f6a1d22bdd54f75a0470360565daa26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dataset_infos.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0fb631df382456589d1b74837f6dc0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "elementary_mathematics/test-00000-of-000(…):   0%|          | 0.00/41.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "250fa64b855b4668bbb94c1bd2e55aba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "elementary_mathematics/validation-00000-(…):   0%|          | 0.00/9.38k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71480db22206459ebe7e483e2be27471"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "elementary_mathematics/dev-00000-of-0000(…):   0%|          | 0.00/4.55k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93e0955d5a2848f680f30db73fff9775"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/378 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1315208aa6524b74acf38ef0bb666532"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/41 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f667567100654c48895ae28747bc3084"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dc6e5519db749f98ed15e74b42eff91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MMLU Dataset Loaded. Size: 378 samples.\n",
            "Global setup complete. Ready for Step 2.\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "wandb.login()\n",
        "\n",
        "if 'results_table' not in globals():\n",
        "    results_table = []\n",
        "\n",
        "print(\"Loading MMLU Dataset...\")\n",
        "# We use 'elementary_mathematics' as the subset for this project\n",
        "try:\n",
        "    mmlu_dataset = concatenate_datasets([\n",
        "        load_dataset(\"cais/mmlu\", \"elementary_mathematics\", split='test')\n",
        "    ])\n",
        "    print(f\"MMLU Dataset Loaded. Size: {len(mmlu_dataset)} samples.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading MMLU: {e}\")\n",
        "    from datasets import Dataset\n",
        "    mmlu_dataset = Dataset.from_dict({\n",
        "        \"question\": [\"1+1=?\"], \"choices\": [[\"1\", \"2\", \"3\", \"4\"]], \"answer\": [1]\n",
        "    })\n",
        "\n",
        "print(\"Global setup complete. Ready for Step 2.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oSacR3QplT_H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "outputId": "0de30342-28ee-4de5-9e49-5e03ffd4ad57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "Selected Model: Qwen/Qwen2.5-0.5B-Instruct\n",
            "========================================\n",
            "Loading FP16 Baseline (This may take a minute)...\n",
            "--- Evaluating: FP16 Baseline ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MMLU Eval: 100%|██████████| 200/200 [00:06<00:00, 31.60it/s]\n",
            "Computing PPL:   0%|          | 0/3 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results -> Acc: 25.50%, PPL: 8.35, Latency: 1.47s, Mem: 1.13GB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251213_223438-e2qem56e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yq171014-columbia-university/Test_Run/runs/e2qem56e' target=\"_blank\">Qwen2.5-0.5B-Instruct-Baseline</a></strong> to <a href='https://wandb.ai/yq171014-columbia-university/Test_Run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yq171014-columbia-university/Test_Run' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yq171014-columbia-university/Test_Run/runs/e2qem56e' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run/runs/e2qem56e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁</td></tr><tr><td>Flip_Rate</td><td>▁</td></tr><tr><td>Latency</td><td>▁</td></tr><tr><td>Memory</td><td>▁</td></tr><tr><td>Perplexity</td><td>▁</td></tr><tr><td>Threshold</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.255</td></tr><tr><td>Flip_Rate</td><td>0</td></tr><tr><td>Latency</td><td>1.46656</td></tr><tr><td>Memory</td><td>1.13149</td></tr><tr><td>Method</td><td>Baseline</td></tr><tr><td>Perplexity</td><td>8.35013</td></tr><tr><td>Threshold</td><td>0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Qwen2.5-0.5B-Instruct-Baseline</strong> at: <a href='https://wandb.ai/yq171014-columbia-university/Test_Run/runs/e2qem56e' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run/runs/e2qem56e</a><br> View project at: <a href='https://wandb.ai/yq171014-columbia-university/Test_Run' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251213_223438-e2qem56e/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Loaded & Evaluated.\n"
          ]
        }
      ],
      "source": [
        "# Model Selection & Baseline Evaluation\n",
        "\n",
        "# Select model\n",
        "CURRENT_MODEL_ID = MODELS_TO_TEST[0]\n",
        "\n",
        "print(f\"{'='*40}\\nSelected Model: {CURRENT_MODEL_ID}\\n{'='*40}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(CURRENT_MODEL_ID)\n",
        "print(\"Loading FP16 Baseline (This may take a minute)...\")\n",
        "model_fp16 = AutoModelForCausalLM.from_pretrained(\n",
        "    CURRENT_MODEL_ID,\n",
        "    dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Evaluate Baseline\n",
        "base_acc, base_ppl, base_lat, base_mem, base_preds = evaluate_full_suite(\n",
        "    model_fp16, tokenizer, mmlu_dataset, \"FP16 Baseline\"\n",
        ")\n",
        "\n",
        "# Log Baseline to WandB\n",
        "run = wandb.init(project=WANDB_PROJECT_NAME, name=f\"{CURRENT_MODEL_ID.split('/')[-1]}-Baseline\", reinit=True)\n",
        "wandb.log({\n",
        "    \"Accuracy\": base_acc,\n",
        "    \"Perplexity\": base_ppl,\n",
        "    \"Latency\": base_lat,\n",
        "    \"Memory\": base_mem,\n",
        "    \"Threshold\": 0,\n",
        "    \"Flip_Rate\": 0.0,\n",
        "    \"Method\": \"Baseline\"\n",
        "})\n",
        "run.finish()\n",
        "\n",
        "# Store in Results Table\n",
        "results_table.append({\n",
        "    \"Model\": CURRENT_MODEL_ID,\n",
        "    \"Method\": \"FP16 Baseline\",\n",
        "    \"Threshold\": 0,\n",
        "    \"Acc\": base_acc,\n",
        "    \"Flip\": 0.0,\n",
        "    \"PPL\": base_ppl,\n",
        "    \"Latency\": base_lat,\n",
        "    \"Mem\": base_mem\n",
        "})\n",
        "\n",
        "print(\"Baseline Loaded & Evaluated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "N1VaDnQZlddP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8f48c4-de2c-4064-df6f-e66dcdc552df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing Calibration Data...\n",
            "Moving FP16 model to CPU to free up VRAM...\n",
            "VRAM Cleared. Ready for Experiments.\n"
          ]
        }
      ],
      "source": [
        "# Profiling & Offloading\n",
        "print(\"Preparing Calibration Data...\")\n",
        "calib_data = tokenizer(\n",
        "    \"\\n\\n\".join(load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")[\"text\"][:10]),\n",
        "    return_tensors=\"pt\"\n",
        ").input_ids.to(device)\n",
        "\n",
        "granularity_mode = 'block' if ENABLE_BLOCK_WISE else 'layer'\n",
        "\n",
        "# Offload FP16 Model to CPU to save memory\n",
        "print(\"Moving FP16 model to CPU to free up VRAM...\")\n",
        "model_fp16.cpu()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"VRAM Cleared. Ready for Experiments.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment A: Threshold Study (NF4)\n",
        "\n",
        "print(f\"\\n--- Starting Experiment A: Threshold Study ({CURRENT_MODEL_ID}) ---\")\n",
        "\n",
        "print(\"Loading NF4 Model for Profiling & Incremental Surgery...\")\n",
        "model_nf4 = AutoModelForCausalLM.from_pretrained(\n",
        "    CURRENT_MODEL_ID,\n",
        "    quantization_config=BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16\n",
        "    ),\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "sensitivity_map = profile_restoration_sensitivity(\n",
        "    model_q=model_nf4,\n",
        "    model_ref=model_fp16,\n",
        "    calib_input=calib_data,\n",
        "    granularity='block' if ENABLE_BLOCK_WISE else 'layer'\n",
        ")\n",
        "sorted_layers = sorted(sensitivity_map.items(), key=lambda x: x[1], reverse=True)\n",
        "all_layer_names = [n for n, s in sorted_layers]\n",
        "\n",
        "# Experiment loop\n",
        "sorted_thresholds = sorted(SENSITIVITY_THRESHOLDS)\n",
        "current_restored_count = 0\n",
        "\n",
        "for threshold in sorted_thresholds:\n",
        "    print(f\"\\nTargeting Threshold: {threshold:.0%} kept in FP16\")\n",
        "\n",
        "    target_count = int(len(all_layer_names) * threshold)\n",
        "\n",
        "    layers_to_fix_now = all_layer_names[current_restored_count : target_count]\n",
        "\n",
        "    if layers_to_fix_now:\n",
        "        print(f\"Restoring {len(layers_to_fix_now)} additional layers...\")\n",
        "        perform_surgery(model_nf4, layers_to_fix_now, model_fp16)\n",
        "        current_restored_count = target_count\n",
        "    else:\n",
        "        print(\"No new layers to restore for this step.\")\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=WANDB_PROJECT_NAME,\n",
        "        name=f\"{CURRENT_MODEL_ID.split('/')[-1]}-NF4-{threshold}\",\n",
        "        config={\"model\": CURRENT_MODEL_ID, \"threshold\": threshold, \"method\": \"KLD-NF4\"},\n",
        "        reinit=True\n",
        "    )\n",
        "\n",
        "    acc, ppl, lat, mem, preds = evaluate_full_suite(\n",
        "        model_nf4, tokenizer, mmlu_dataset, f\"KLD-NF4-{threshold}\"\n",
        "    )\n",
        "\n",
        "    flip = calculate_flip_rate(base_preds, preds)\n",
        "\n",
        "    wandb.log({\n",
        "        \"Accuracy\": acc, \"Perplexity\": ppl, \"Latency\": lat,\n",
        "        \"Memory\": mem, \"Flip_Rate\": flip, \"Threshold\": threshold\n",
        "    })\n",
        "\n",
        "    results_table.append({\n",
        "        \"Model\": CURRENT_MODEL_ID,\n",
        "        \"Method\": \"KLD-NF4\",\n",
        "        \"Threshold\": threshold,\n",
        "        \"Acc\": acc,\n",
        "        \"Flip\": flip,\n",
        "        \"PPL\": ppl,\n",
        "        \"Latency\": lat,\n",
        "        \"Mem\": mem\n",
        "    })\n",
        "\n",
        "    run.finish()\n",
        "\n",
        "# Cleanup\n",
        "del model_nf4\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Experiment A Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mjy30DqFzRLN",
        "outputId": "37e43040-6e2a-4fb9-c4e0-58f320e57ba6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Experiment A: Threshold Study (Qwen/Qwen2.5-0.5B-Instruct) ---\n",
            "Loading NF4 Model for Profiling & Incremental Surgery...\n",
            "Profiling Restoration Sensitivity (Granularity: layer)...\n",
            "Initial Quantized KLD: 86.875000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Profiling Layers: 100%|██████████| 240/240 [00:15<00:00, 15.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Targeting Threshold: 0% kept in FP16\n",
            "No new layers to restore for this step.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251213_223459-r5ry4k0i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yq171014-columbia-university/Test_Run/runs/r5ry4k0i' target=\"_blank\">Qwen2.5-0.5B-Instruct-NF4-0.0</a></strong> to <a href='https://wandb.ai/yq171014-columbia-university/Test_Run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yq171014-columbia-university/Test_Run' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yq171014-columbia-university/Test_Run/runs/r5ry4k0i' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run/runs/r5ry4k0i</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluating: KLD-NF4-0.0 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MMLU Eval: 100%|██████████| 200/200 [00:12<00:00, 15.48it/s]\n",
            "Computing PPL:   0%|          | 0/3 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results -> Acc: 26.50%, PPL: 8.86, Latency: 2.20s, Mem: 1.39GB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁</td></tr><tr><td>Flip_Rate</td><td>▁</td></tr><tr><td>Latency</td><td>▁</td></tr><tr><td>Memory</td><td>▁</td></tr><tr><td>Perplexity</td><td>▁</td></tr><tr><td>Threshold</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.265</td></tr><tr><td>Flip_Rate</td><td>0.63</td></tr><tr><td>Latency</td><td>2.19706</td></tr><tr><td>Memory</td><td>1.38526</td></tr><tr><td>Perplexity</td><td>8.85514</td></tr><tr><td>Threshold</td><td>0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Qwen2.5-0.5B-Instruct-NF4-0.0</strong> at: <a href='https://wandb.ai/yq171014-columbia-university/Test_Run/runs/r5ry4k0i' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run/runs/r5ry4k0i</a><br> View project at: <a href='https://wandb.ai/yq171014-columbia-university/Test_Run' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251213_223459-r5ry4k0i/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Targeting Threshold: 5% kept in FP16\n",
            "Restoring 12 additional layers...\n",
            "Surgery: Replacing 12 Sensitive Layers with FP16...\n",
            "Surgery Complete: 12 layers restored.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251213_223521-9mc7uqnr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yq171014-columbia-university/Test_Run/runs/9mc7uqnr' target=\"_blank\">Qwen2.5-0.5B-Instruct-NF4-0.05</a></strong> to <a href='https://wandb.ai/yq171014-columbia-university/Test_Run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yq171014-columbia-university/Test_Run' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yq171014-columbia-university/Test_Run/runs/9mc7uqnr' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run/runs/9mc7uqnr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluating: KLD-NF4-0.05 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MMLU Eval: 100%|██████████| 200/200 [00:11<00:00, 16.92it/s]\n",
            "Computing PPL:   0%|          | 0/3 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results -> Acc: 25.00%, PPL: 8.65, Latency: 2.04s, Mem: 1.57GB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁</td></tr><tr><td>Flip_Rate</td><td>▁</td></tr><tr><td>Latency</td><td>▁</td></tr><tr><td>Memory</td><td>▁</td></tr><tr><td>Perplexity</td><td>▁</td></tr><tr><td>Threshold</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.25</td></tr><tr><td>Flip_Rate</td><td>0.345</td></tr><tr><td>Latency</td><td>2.04451</td></tr><tr><td>Memory</td><td>1.57144</td></tr><tr><td>Perplexity</td><td>8.65477</td></tr><tr><td>Threshold</td><td>0.05</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Qwen2.5-0.5B-Instruct-NF4-0.05</strong> at: <a href='https://wandb.ai/yq171014-columbia-university/Test_Run/runs/9mc7uqnr' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run/runs/9mc7uqnr</a><br> View project at: <a href='https://wandb.ai/yq171014-columbia-university/Test_Run' target=\"_blank\">https://wandb.ai/yq171014-columbia-university/Test_Run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251213_223521-9mc7uqnr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment A Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRuBYJfulhqt"
      },
      "outputs": [],
      "source": [
        "# Experiment A: Threshold Study (NF4)\n",
        "\n",
        "print(f\"\\n--- Starting Experiment A: Threshold Study ({CURRENT_MODEL_ID}) ---\")\n",
        "\n",
        "# 0.0 = Standard NF4 (No KLD)\n",
        "# 0.05 = KLD-Guided (5% layers restored)\n",
        "thresholds_to_test = [0.0, 0.01, 0.05, 0.10, 0.20]\n",
        "\n",
        "for threshold in thresholds_to_test:\n",
        "    print(f\"\\nTesting Threshold: {threshold:.0%} kept in FP16\")\n",
        "\n",
        "    run_name = f\"{CURRENT_MODEL_ID.split('/')[-1]}-NF4-{threshold}\"\n",
        "    run = wandb.init(\n",
        "        project=WANDB_PROJECT_NAME,\n",
        "        name=run_name,\n",
        "        config={\"model\": CURRENT_MODEL_ID, \"threshold\": threshold, \"method\": \"KLD-NF4\"}\n",
        "    )\n",
        "\n",
        "    # 1. Identify Layers to Keep\n",
        "    sorted_layers = sorted(sensitivity_map.items(), key=lambda x: x[1], reverse=True)\n",
        "    num_keep = int(len(sorted_layers) * threshold)\n",
        "    sensitive_layers = [n for n, s in sorted_layers[:num_keep]]\n",
        "\n",
        "    # 2. Load Standard NF4 Model\n",
        "    model_nf4 = AutoModelForCausalLM.from_pretrained(\n",
        "        CURRENT_MODEL_ID,\n",
        "        quantization_config=BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16\n",
        "        ),\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    # 3. Perform Surgery (Only if threshold > 0)\n",
        "    if len(sensitive_layers) > 0:\n",
        "        perform_surgery(model_nf4, sensitive_layers, model_fp16)\n",
        "\n",
        "    # 4. Evaluate\n",
        "    acc, ppl, lat, mem, preds = evaluate_full_suite(\n",
        "        model_nf4, tokenizer, mmlu_dataset, f\"KLD-NF4-{threshold}\"\n",
        "    )\n",
        "\n",
        "    # 5. Calculate Flip Rate\n",
        "    flip = calculate_flip_rate(base_preds, preds)\n",
        "\n",
        "    # 6. Log & Save (FIXED)\n",
        "    wandb.log({\n",
        "        \"Accuracy\": acc, \"Perplexity\": ppl, \"Latency\": lat,\n",
        "        \"Memory\": mem, \"Flip_Rate\": flip, \"Threshold\": threshold\n",
        "    })\n",
        "\n",
        "    results_table.append({\n",
        "        \"Model\": CURRENT_MODEL_ID,\n",
        "        \"Method\": \"KLD-NF4\",\n",
        "        \"Threshold\": threshold,\n",
        "        \"Acc\": acc,\n",
        "        \"Flip\": flip,   # <--- Fixed\n",
        "        \"PPL\": ppl,\n",
        "        \"Latency\": lat, # <--- Fixed\n",
        "        \"Mem\": mem\n",
        "    })\n",
        "\n",
        "    del model_nf4\n",
        "    torch.cuda.empty_cache()\n",
        "    run.finish()\n",
        "\n",
        "print(\"Experiment A Complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di8YREEZlkOu"
      },
      "outputs": [],
      "source": [
        "# Experiment B: FP8 Comparison\n",
        "\n",
        "if ENABLE_FP8_COMPARISON:\n",
        "    print(f\"\\n--- Starting Experiment B: FP8 Comparison ({CURRENT_MODEL_ID}) ---\")\n",
        "\n",
        "    best_threshold = 0.05\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=WANDB_PROJECT_NAME,\n",
        "        name=f\"{CURRENT_MODEL_ID.split('/')[-1]}-FP8\",\n",
        "        config={\"model\": CURRENT_MODEL_ID, \"method\": \"KLD-FP8\"}\n",
        "    )\n",
        "\n",
        "    # Identify Layers\n",
        "    sorted_layers = sorted(sensitivity_map.items(), key=lambda x: x[1], reverse=True)\n",
        "    sensitive_layers = [n for n, s in sorted_layers[:int(len(sorted_layers)*best_threshold)]]\n",
        "\n",
        "    # Load FP8 (using float8_e4m3fn or equivalent based on your hardware/backend)\n",
        "    model_fp8 = AutoModelForCausalLM.from_pretrained(\n",
        "        CURRENT_MODEL_ID,\n",
        "        torch_dtype=torch.float8_e4m3fn, # Changed from load_in_8bit=True\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    # Surgery\n",
        "    # Note: Ensure perform_surgery handles casting from FP16 to FP8 correctly\n",
        "    perform_surgery(model_fp8, sensitive_layers, model_fp16)\n",
        "\n",
        "    # Evaluate\n",
        "    acc, ppl, lat, mem, preds = evaluate_full_suite(\n",
        "        model_fp8, tokenizer, mmlu_dataset, \"KLD-FP8\"\n",
        "    )\n",
        "\n",
        "    flip = calculate_flip_rate(base_preds, preds)\n",
        "\n",
        "    wandb.log({\n",
        "        \"Accuracy\": acc, \"Perplexity\": ppl, \"Latency\": lat,\n",
        "        \"Memory\": mem, \"Flip_Rate\": flip\n",
        "    })\n",
        "\n",
        "    results_table.append({\n",
        "        \"Model\": CURRENT_MODEL_ID,\n",
        "        \"Method\": \"KLD-FP8\",\n",
        "        \"Threshold\": best_threshold,\n",
        "        \"Acc\": acc,\n",
        "        \"Flip\": flip,\n",
        "        \"PPL\": ppl,\n",
        "        \"Latency\": lat,\n",
        "        \"Mem\": mem\n",
        "    })\n",
        "\n",
        "    del model_fp8\n",
        "    torch.cuda.empty_cache()\n",
        "    run.finish()\n",
        "else:\n",
        "    print(\"Experiment B skipped.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMSThTFmloZu"
      },
      "outputs": [],
      "source": [
        "# Experiment C: Aggressive Compression (Mixed 2-bit/FP16)\n",
        "\n",
        "print(f\"\\n--- Starting Experiment C: Aggressive Compression ({CURRENT_MODEL_ID}) ---\")\n",
        "\n",
        "run = wandb.init(\n",
        "    project=WANDB_PROJECT_NAME,\n",
        "    name=f\"{CURRENT_MODEL_ID.split('/')[-1]}-Aggressive\",\n",
        "    config={\"model\": CURRENT_MODEL_ID, \"method\": \"Mixed-2bit\"}\n",
        ")\n",
        "\n",
        "# 1. Create a Fresh Copy of FP16 on GPU\n",
        "model_aggressive = copy.deepcopy(model_fp16)\n",
        "model_aggressive.to(device)\n",
        "\n",
        "# 2. Identify the \"Safe\" layers (Keep top 5% safe in FP16)\n",
        "sorted_layers = sorted(sensitivity_map.items(), key=lambda x: x[1], reverse=True)\n",
        "sensitive_set = set([n for n, s in sorted_layers[:int(len(sorted_layers)*0.05)]])\n",
        "\n",
        "# 3. Apply Fake 2-bit Quantization to everything ELSE\n",
        "print(\"Applying simulated 2-bit quantization to 95% of layers...\")\n",
        "for name, module in tqdm(model_aggressive.named_modules()):\n",
        "    if isinstance(module, nn.Linear) and name not in sensitive_set:\n",
        "        module.weight.data = fake_quantize_tensor_rtn(module.weight.data, bits=2)\n",
        "\n",
        "# 4. Evaluate\n",
        "acc, ppl, lat, mem, preds = evaluate_full_suite(\n",
        "    model_aggressive, tokenizer, mmlu_dataset, \"Mixed 2-bit/FP16\"\n",
        ")\n",
        "\n",
        "flip = calculate_flip_rate(base_preds, preds)\n",
        "\n",
        "wandb.log({\n",
        "    \"Accuracy\": acc, \"Perplexity\": ppl, \"Latency\": lat,\n",
        "    \"Memory\": mem, \"Flip_Rate\": flip\n",
        "})\n",
        "\n",
        "results_table.append({\n",
        "    \"Model\": CURRENT_MODEL_ID,\n",
        "    \"Method\": \"Mixed-2bit\",\n",
        "    \"Threshold\": 0.05,\n",
        "    \"Acc\": acc,\n",
        "    \"Flip\": flip,   # <--- Fixed\n",
        "    \"PPL\": ppl,\n",
        "    \"Latency\": lat, # <--- Fixed\n",
        "    \"Mem\": mem\n",
        "})\n",
        "\n",
        "del model_aggressive\n",
        "torch.cuda.empty_cache()\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El1ai7m-lqiZ"
      },
      "outputs": [],
      "source": [
        "# Experiment D: AWQ Baseline\n",
        "\n",
        "print(f\"\\n--- Starting Experiment D: AWQ Baseline ({CURRENT_MODEL_ID}) ---\")\n",
        "\n",
        "try:\n",
        "    from llmcompressor.modifiers.awq import AWQModifier\n",
        "    from llmcompressor import oneshot\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=WANDB_PROJECT_NAME,\n",
        "        name=f\"{CURRENT_MODEL_ID.split('/')[-1]}-AWQ\",\n",
        "        config={\"model\": CURRENT_MODEL_ID, \"method\": \"AWQ\"}\n",
        "    )\n",
        "\n",
        "    # 1. Calibration Data\n",
        "    ds = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
        "    calib_data_obj = Dataset.from_dict({\"text\": [text for text in ds[\"text\"] if len(text) > 0][:128]})\n",
        "\n",
        "    # 2. Run Oneshot AWQ\n",
        "    print(\"Running AWQ Oneshot Quantization...\")\n",
        "    recipe = [AWQModifier(targets=\"Linear\", scheme=\"W4A16\")]\n",
        "    oneshot(\n",
        "        model=CURRENT_MODEL_ID,\n",
        "        dataset=calib_data_obj,\n",
        "        recipe=recipe,\n",
        "        output_dir=\"./awq_temp\",\n",
        "        num_calibration_samples=128,\n",
        "        max_seq_length=512,\n",
        "        save_compressed=True\n",
        "    )\n",
        "\n",
        "    # 3. Load & Eval\n",
        "    model_awq = AutoModelForCausalLM.from_pretrained(\n",
        "        \"./awq_temp\", device_map=\"auto\", trust_remote_code=True\n",
        "    )\n",
        "    acc, ppl, lat, mem, preds = evaluate_full_suite(\n",
        "        model_awq, tokenizer, mmlu_dataset, \"AWQ Standard\"\n",
        "    )\n",
        "\n",
        "    flip = calculate_flip_rate(base_preds, preds)\n",
        "\n",
        "    wandb.log({\n",
        "        \"Accuracy\": acc, \"Perplexity\": ppl, \"Latency\": lat,\n",
        "        \"Memory\": mem, \"Flip_Rate\": flip\n",
        "    })\n",
        "\n",
        "    results_table.append({\n",
        "        \"Model\": CURRENT_MODEL_ID,\n",
        "        \"Method\": \"AWQ\",\n",
        "        \"Threshold\": 0,\n",
        "        \"Acc\": acc,\n",
        "        \"Flip\": flip,   # <--- Fixed\n",
        "        \"PPL\": ppl,\n",
        "        \"Latency\": lat, # <--- Fixed\n",
        "        \"Mem\": mem\n",
        "    })\n",
        "\n",
        "    shutil.rmtree(\"./awq_temp\")\n",
        "    del model_awq\n",
        "    torch.cuda.empty_cache()\n",
        "    run.finish()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Skipping AWQ: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-PocD_EKt8Gi"
      },
      "outputs": [],
      "source": [
        "# Experiment E: GPTQ Standard Baseline\n",
        "\n",
        "print(f\"\\n--- Starting Experiment E: GPTQ Baseline ({CURRENT_MODEL_ID}) ---\")\n",
        "\n",
        "try:\n",
        "    from llmcompressor.modifiers.quantization import GPTQModifier\n",
        "    from llmcompressor import oneshot\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=WANDB_PROJECT_NAME,\n",
        "        name=f\"{CURRENT_MODEL_ID.split('/')[-1]}-GPTQ\",\n",
        "        config={\"model\": CURRENT_MODEL_ID, \"method\": \"GPTQ\"}\n",
        "    )\n",
        "\n",
        "    ds = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
        "    calib_data_obj = Dataset.from_dict({\"text\": [text for text in ds[\"text\"] if len(text) > 0][:128]})\n",
        "\n",
        "    # W4A16 = 4-bit Weights, 16-bit Activations\n",
        "    recipe = [\n",
        "        GPTQModifier(\n",
        "            targets=\"Linear\",\n",
        "            scheme=\"W4A16\",\n",
        "            ignore=[\"lm_head\"],\n",
        "            dampening_frac=0.01\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"Running GPTQ Optimization...\")\n",
        "    oneshot(\n",
        "        model=CURRENT_MODEL_ID,\n",
        "        dataset=calib_data_obj,\n",
        "        recipe=recipe,\n",
        "        output_dir=\"./gptq_temp\",\n",
        "        num_calibration_samples=128,\n",
        "        max_seq_length=512,\n",
        "        save_compressed=True\n",
        "    )\n",
        "\n",
        "    print(\"Loading GPTQ Model...\")\n",
        "    model_gptq = AutoModelForCausalLM.from_pretrained(\n",
        "        \"./gptq_temp\",\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    acc, ppl, lat, mem, preds = evaluate_full_suite(\n",
        "        model_gptq, tokenizer, mmlu_dataset, \"GPTQ Standard\"\n",
        "    )\n",
        "\n",
        "    flip = calculate_flip_rate(base_preds, preds)\n",
        "\n",
        "    wandb.log({\n",
        "        \"Accuracy\": acc, \"Perplexity\": ppl, \"Latency\": lat,\n",
        "        \"Memory\": mem, \"Flip_Rate\": flip\n",
        "    })\n",
        "\n",
        "    results_table.append({\n",
        "        \"Model\": CURRENT_MODEL_ID,\n",
        "        \"Method\": \"GPTQ\",\n",
        "        \"Threshold\": 0,\n",
        "        \"Acc\": acc,\n",
        "        \"Flip\": flip,   # <--- Fixed\n",
        "        \"PPL\": ppl,\n",
        "        \"Latency\": lat, # <--- Fixed\n",
        "        \"Mem\": mem\n",
        "    })\n",
        "\n",
        "    shutil.rmtree(\"./gptq_temp\")\n",
        "    del model_gptq\n",
        "    torch.cuda.empty_cache()\n",
        "    run.finish()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Skipping GPTQ: {e}\")\n",
        "\n",
        "print(\"Experiment E Complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf3mRkStVEeU"
      },
      "source": [
        "# Visualization & Reporting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42iK-WKQdS--"
      },
      "source": [
        "QWen:\n",
        "```\n",
        "\n",
        "                        Model         Method  Threshold    Acc   Flip  \\\n",
        "0  Qwen/Qwen2.5-0.5B-Instruct  FP16 Baseline       0.00  0.250  0.000   \n",
        "1  Qwen/Qwen2.5-0.5B-Instruct        KLD-NF4       0.00  0.265  0.630   \n",
        "2  Qwen/Qwen2.5-0.5B-Instruct        KLD-NF4       0.01  0.265  0.630   \n",
        "3  Qwen/Qwen2.5-0.5B-Instruct        KLD-NF4       0.05  0.280  0.430   \n",
        "4  Qwen/Qwen2.5-0.5B-Instruct        KLD-NF4       0.10  0.280  0.395   \n",
        "5  Qwen/Qwen2.5-0.5B-Instruct        KLD-NF4       0.20  0.290  0.305   \n",
        "6  Qwen/Qwen2.5-0.5B-Instruct       KLD-Int8       0.05  0.250  0.155   \n",
        "7  Qwen/Qwen2.5-0.5B-Instruct     Mixed-2bit       0.05  0.225  0.465   \n",
        "8  Qwen/Qwen2.5-0.5B-Instruct            AWQ       0.00  0.240  0.430   \n",
        "9  Qwen/Qwen2.5-0.5B-Instruct           GPTQ       0.00  0.205  0.385   \n",
        "\n",
        "             PPL   Latency       Mem  \n",
        "0       8.350414  2.043066  0.942955  \n",
        "1       8.855442  2.643480  0.458393  \n",
        "2       8.855442  2.512811  0.711964  \n",
        "3       8.830623  2.543613  0.949767  \n",
        "4       8.774139  2.509315  1.014822  \n",
        "5       8.657179  2.484945  1.139766  \n",
        "6       8.353897  7.321452  1.071951  \n",
        "7  537496.375000  1.837433  1.131078  \n",
        "8      12.012968  5.784297  3.139405  \n",
        "9       9.055728  4.997509  1.655096\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U6n0PN55ltb-"
      },
      "outputs": [],
      "source": [
        "# View Results Table\n",
        "df = pd.DataFrame(results_table)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "odLpWuQ1YIGb"
      },
      "outputs": [],
      "source": [
        "# Save Results to Google Drive\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "# This will trigger a popup asking for permission\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e0Km1YZbYTuM"
      },
      "outputs": [],
      "source": [
        "# 2. Define Filename\n",
        "# We include the model name to avoid overwriting previous results\n",
        "model_name = CURRENT_MODEL_ID.split('/')[-1] if 'CURRENT_MODEL_ID' in globals() else \"experiment\"\n",
        "filename = f\"//content/drive/MyDrive/Columbia-LLMSeminar/SLLM project/Mena/{model_name}_1204results.csv\"\n",
        "\n",
        "# 3. Create Directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "# 4. Save\n",
        "if results_table:\n",
        "    df = pd.DataFrame(results_table)\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"✅ Success! Results saved to Google Drive at:\\n{filename}\")\n",
        "else:\n",
        "    print(\"⚠️ Warning: results_table is empty. Nothing to save.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ezdLtrN40RqA"
      },
      "outputs": [],
      "source": [
        "# Log Final Summary to WandB\n",
        "\n",
        "print(\"\\n--- Uploading Final Report to Weights & Biases ---\")\n",
        "\n",
        "# 1. Initialize a generic \"Summary\" run\n",
        "run = wandb.init(\n",
        "    project=WANDB_PROJECT_NAME,\n",
        "    name=\"Final-Summary-Report\",\n",
        "    job_type=\"report\"\n",
        ")\n",
        "\n",
        "# 2. Upload the Master Data Table\n",
        "# This allows you to query/sort your results in the WandB UI\n",
        "if results_table:\n",
        "    tbl = wandb.Table(dataframe=pd.DataFrame(results_table))\n",
        "    wandb.log({\"Experiment_Results_Raw\": tbl})\n",
        "\n",
        "# 3. Upload the Matplotlib Images (from Cell 7)\n",
        "# This saves the static PNGs you just generated into the cloud\n",
        "import os\n",
        "image_files = ['graph1_sweet_spot.png', 'graph2_flip_rate.png', 'graph3_efficiency.png']\n",
        "\n",
        "for img_file in image_files:\n",
        "    if os.path.exists(img_file):\n",
        "        wandb.log({img_file.replace(\".png\", \"\"): wandb.Image(img_file)})\n",
        "        print(f\"Uploaded {img_file}\")\n",
        "    else:\n",
        "        print(f\"Warning: {img_file} not found. Did you run Cell 7?\")\n",
        "\n",
        "# 4. Create an Interactive Custom Chart (Efficiency Frontier)\n",
        "# This creates a native WandB chart where you can hover over dots to see model details\n",
        "if results_table:\n",
        "    data = [[r['Method'], r['Threshold'], r['Mem'], r['PPL']] for r in results_table]\n",
        "    table = wandb.Table(data=data, columns=[\"Method\", \"Threshold\", \"Memory\", \"Perplexity\"])\n",
        "\n",
        "    # Custom Scatter Plot definition\n",
        "    wandb.log({\n",
        "        \"Efficiency_Frontier_Interactive\": wandb.plot.scatter(\n",
        "            table, \"Memory\", \"Perplexity\", title=\"Efficiency Frontier (Interactive)\"\n",
        "        )\n",
        "    })\n",
        "\n",
        "run.finish()\n",
        "print(\"Upload Complete. Check your WandB Dashboard!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4TAmbF1fhls_"
      },
      "outputs": [],
      "source": [
        "# Visualization & Reporting\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Prepare Data\n",
        "if not results_table:\n",
        "    print(\"No results to plot! Run the experiments first.\")\n",
        "else:\n",
        "    df = pd.DataFrame(results_table)\n",
        "\n",
        "    # Optional: Save raw data to CSV for your paper\n",
        "    df.to_csv(\"experiment_results.csv\", index=False)\n",
        "    print(\"Results saved to 'experiment_results.csv'\")\n",
        "\n",
        "    # Filter for the model we just tested (or select the first one available)\n",
        "    target_model = CURRENT_MODEL_ID if 'CURRENT_MODEL_ID' in globals() else df['Model'].unique()[0]\n",
        "    model_df = df[df['Model'] == target_model]\n",
        "\n",
        "    print(f\"\\nGenerating Plots for: {target_model}\")\n",
        "\n",
        "    # Set Style\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "    # ==============================================================================\n",
        "    # Graph 1: The \"Sweet Spot\" (Accuracy vs. Threshold)\n",
        "    # Goal: Show that 5% FP16 recovery beats the Standard NF4 baseline\n",
        "    # ==============================================================================\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Filter for KLD-NF4 data points\n",
        "    nf4_data = model_df[model_df['Method'] == 'KLD-NF4'].sort_values('Threshold')\n",
        "\n",
        "    # Plot the KLD Curve\n",
        "    sns.lineplot(data=nf4_data, x='Threshold', y='Acc', marker='o', label='KLD-Guided NF4', linewidth=2.5)\n",
        "\n",
        "    # Plot Baseline Reference (FP16)\n",
        "    baseline_acc = model_df[model_df['Method'] == 'FP16 Baseline']['Acc'].values[0]\n",
        "    plt.axhline(y=baseline_acc, color='green', linestyle='--', label=f'FP16 Baseline ({baseline_acc:.1%})')\n",
        "\n",
        "    # Formatting\n",
        "    plt.title(f'The Sweet Spot: Accuracy vs. FP16 Retention ({target_model})', fontsize=14)\n",
        "    plt.xlabel('Percentage of Layers Kept in FP16', fontsize=12)\n",
        "    plt.ylabel('MMLU Accuracy', fontsize=12)\n",
        "    plt.legend()\n",
        "\n",
        "    # Fix X-Axis to show percentages nicely\n",
        "    plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.0%}'))\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('graph1_sweet_spot.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # ==============================================================================\n",
        "    # Graph 2: Flip Rate Reduction (The \"Stability\" Metric)\n",
        "    # Goal: Show that KLD-Guided significantly reduces answer flips compared to 0%\n",
        "    # ==============================================================================\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot Flip Rate Curve\n",
        "    sns.barplot(data=nf4_data, x='Threshold', y='Flip', hue='Threshold', palette=\"viridis\", legend=False)\n",
        "\n",
        "    # Formatting\n",
        "    plt.title(f'Impact of KLD Guidance on Output Stability', fontsize=14)\n",
        "    plt.xlabel('Percentage of Layers Kept in FP16', fontsize=12)\n",
        "    plt.ylabel('Flip Rate (Lower is Better)', fontsize=12)\n",
        "\n",
        "    # Fix Y-Axis to percentage\n",
        "    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0%}'))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('graph2_flip_rate.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # ==============================================================================\n",
        "    # Graph 3: Efficiency Frontier (Perplexity vs. Memory)\n",
        "    # Goal: Compare ALL methods (NF4, Int8, AWQ, Mixed-2bit)\n",
        "    # Ideal Position: Bottom-Left Corner (Low Memory, Low Perplexity)\n",
        "    # ==============================================================================\n",
        "    plt.figure(figsize=(10, 7))\n",
        "\n",
        "    # Create Scatter Plot\n",
        "    # We remove the Baseline from this plot if it skews the scale too much,\n",
        "    # but usually it's good to keep it to show the Memory gap.\n",
        "    sns.scatterplot(\n",
        "        data=model_df,\n",
        "        x='Mem',\n",
        "        y='PPL',\n",
        "        hue='Method',\n",
        "        style='Method',\n",
        "        s=200, # Marker size\n",
        "        alpha=0.8\n",
        "    )\n",
        "\n",
        "    # Annotate points\n",
        "    for i in range(model_df.shape[0]):\n",
        "        row = model_df.iloc[i]\n",
        "        plt.text(\n",
        "            row.Mem + 0.02,\n",
        "            row.PPL + 0.02,\n",
        "            f\"{row.Method}\\n({row.Threshold:.0%})\",\n",
        "            fontsize=9\n",
        "        )\n",
        "\n",
        "    # Formatting\n",
        "    plt.title(f'Efficiency Frontier: Memory vs. Perplexity', fontsize=14)\n",
        "    plt.xlabel('Memory Usage (GB)', fontsize=12)\n",
        "    plt.ylabel('Perplexity (Lower is Better)', fontsize=12)\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('graph3_efficiency.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # ==============================================================================\n",
        "    # Final Data Table\n",
        "    # ==============================================================================\n",
        "    print(\"\\n=== Final Master Results Table ===\")\n",
        "    # Reorder columns for readability\n",
        "    cols = ['Model', 'Method', 'Threshold', 'Acc', 'Flip', 'PPL', 'Mem']\n",
        "    display_df = model_df[cols].sort_values(['Method', 'Threshold'])\n",
        "    print(display_df.to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f6a1d22bdd54f75a0470360565daa26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fb6b9d92dd046f69cc13e8992def2cd",
              "IPY_MODEL_c5113a70acae4327ad31f53b186a0e5b",
              "IPY_MODEL_bec5839fd7224fa6a747a151fe7e73f3"
            ],
            "layout": "IPY_MODEL_c6c4600fec1f4ee9b6f65c8cbba90315"
          }
        },
        "4fb6b9d92dd046f69cc13e8992def2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18260c398ae2473db62188f4fbc6b12b",
            "placeholder": "​",
            "style": "IPY_MODEL_cbc8a500c693486ebf24c9ac6417cb25",
            "value": "README.md: "
          }
        },
        "c5113a70acae4327ad31f53b186a0e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2adbfb0d2f15459abd2612692cb9545c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4955db1f4946430eaec6e03617741628",
            "value": 1
          }
        },
        "bec5839fd7224fa6a747a151fe7e73f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d3449ad04b0495191da22cb4a08af64",
            "placeholder": "​",
            "style": "IPY_MODEL_513aa422f9a044cbb4e747aec80afcc3",
            "value": " 53.2k/? [00:00&lt;00:00, 5.77MB/s]"
          }
        },
        "c6c4600fec1f4ee9b6f65c8cbba90315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18260c398ae2473db62188f4fbc6b12b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc8a500c693486ebf24c9ac6417cb25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2adbfb0d2f15459abd2612692cb9545c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4955db1f4946430eaec6e03617741628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d3449ad04b0495191da22cb4a08af64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "513aa422f9a044cbb4e747aec80afcc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0fb631df382456589d1b74837f6dc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7375d9e08245474eb8228e06a2c86ed6",
              "IPY_MODEL_729460a1cc9d4bd1b60ce828fc8f22eb",
              "IPY_MODEL_3d358558a7cf413daafdd5ce8364f78d"
            ],
            "layout": "IPY_MODEL_d08b54140abc44ea82a6f09ff8ac2b60"
          }
        },
        "7375d9e08245474eb8228e06a2c86ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2838fad0bbc45968de578b3ef3141eb",
            "placeholder": "​",
            "style": "IPY_MODEL_01a60a70601c4da1a88ec10b44c5afce",
            "value": "dataset_infos.json: "
          }
        },
        "729460a1cc9d4bd1b60ce828fc8f22eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be09d6fb532940b0a3fa0a0f6aa09725",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddfc6d4894424dadb3f9ec83a97152be",
            "value": 1
          }
        },
        "3d358558a7cf413daafdd5ce8364f78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_163aaf7689fe4eed816e463960eca75c",
            "placeholder": "​",
            "style": "IPY_MODEL_989d05854ef34d0a98d2fca30bfa1221",
            "value": " 138k/? [00:00&lt;00:00, 10.4MB/s]"
          }
        },
        "d08b54140abc44ea82a6f09ff8ac2b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2838fad0bbc45968de578b3ef3141eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01a60a70601c4da1a88ec10b44c5afce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be09d6fb532940b0a3fa0a0f6aa09725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ddfc6d4894424dadb3f9ec83a97152be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "163aaf7689fe4eed816e463960eca75c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "989d05854ef34d0a98d2fca30bfa1221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "250fa64b855b4668bbb94c1bd2e55aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_269cafa99234414fa0d9b68372eabc42",
              "IPY_MODEL_52c7d96fd80242039309203b4f71db76",
              "IPY_MODEL_2a2f7097322f412f895355c7cc81fd1f"
            ],
            "layout": "IPY_MODEL_025c1070e8bc40ac9609ef3443a3c0c3"
          }
        },
        "269cafa99234414fa0d9b68372eabc42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f68645bd97164993947e136b20c8823e",
            "placeholder": "​",
            "style": "IPY_MODEL_c18638b0c0004acda058d91ec004915e",
            "value": "elementary_mathematics/test-00000-of-000(…): 100%"
          }
        },
        "52c7d96fd80242039309203b4f71db76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a217bec1e77c4dc287ea6fd3140c9a66",
            "max": 41056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb5dea71b8284d42b0e977d904859c1c",
            "value": 41056
          }
        },
        "2a2f7097322f412f895355c7cc81fd1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd428a3539d545a59013ecc076b95811",
            "placeholder": "​",
            "style": "IPY_MODEL_5effcc6158c74e99bf5301584353d97e",
            "value": " 41.1k/41.1k [00:01&lt;00:00, 27.0kB/s]"
          }
        },
        "025c1070e8bc40ac9609ef3443a3c0c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f68645bd97164993947e136b20c8823e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c18638b0c0004acda058d91ec004915e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a217bec1e77c4dc287ea6fd3140c9a66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb5dea71b8284d42b0e977d904859c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd428a3539d545a59013ecc076b95811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5effcc6158c74e99bf5301584353d97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71480db22206459ebe7e483e2be27471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49cdc7f0359a47879375170013555f36",
              "IPY_MODEL_acf9ede1181649ea843b6556d2a07b82",
              "IPY_MODEL_b83b7c3ebb5245a1a8e5b474d574b53b"
            ],
            "layout": "IPY_MODEL_ba1c1d1d5f3b4cae95414b3da8b7d146"
          }
        },
        "49cdc7f0359a47879375170013555f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa55ae4c1092482db1c32ccab9c9c25c",
            "placeholder": "​",
            "style": "IPY_MODEL_ed101b991ff74d56b9d67185cda1bb52",
            "value": "elementary_mathematics/validation-00000-(…): 100%"
          }
        },
        "acf9ede1181649ea843b6556d2a07b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_153cb404848749ada4ab195ea40a5dbc",
            "max": 9384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57e94a94e1fd4b62a49d43374aeea0f0",
            "value": 9384
          }
        },
        "b83b7c3ebb5245a1a8e5b474d574b53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b2fd72f73154c27981fbf79f5b92025",
            "placeholder": "​",
            "style": "IPY_MODEL_452368a0f9654acaafa36e1056f548a0",
            "value": " 9.38k/9.38k [00:00&lt;00:00, 18.2kB/s]"
          }
        },
        "ba1c1d1d5f3b4cae95414b3da8b7d146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa55ae4c1092482db1c32ccab9c9c25c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed101b991ff74d56b9d67185cda1bb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "153cb404848749ada4ab195ea40a5dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57e94a94e1fd4b62a49d43374aeea0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b2fd72f73154c27981fbf79f5b92025": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "452368a0f9654acaafa36e1056f548a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93e0955d5a2848f680f30db73fff9775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8401c4cb5a4643f58de3af1d2ec4c584",
              "IPY_MODEL_2daaa8f942b244f0b9a68150e0e823d9",
              "IPY_MODEL_66bddc3fd6cc4af994a858806c1488cc"
            ],
            "layout": "IPY_MODEL_8bc34368480448bc82f5d8b0034e16fd"
          }
        },
        "8401c4cb5a4643f58de3af1d2ec4c584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f4311d97b43416ba95a2b52dfc5913a",
            "placeholder": "​",
            "style": "IPY_MODEL_85e0e5ff517249d1927fcbaa3c0f0b05",
            "value": "elementary_mathematics/dev-00000-of-0000(…): 100%"
          }
        },
        "2daaa8f942b244f0b9a68150e0e823d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94dec1e92d0348ec8fe9ae31068f1606",
            "max": 4547,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d17b6f00b1b44d24af6315eaae00b1e1",
            "value": 4547
          }
        },
        "66bddc3fd6cc4af994a858806c1488cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_365a4e4a0611478f8b51179f32521caa",
            "placeholder": "​",
            "style": "IPY_MODEL_028a1261e460416bb4de2d695da73b2e",
            "value": " 4.55k/4.55k [00:00&lt;00:00, 8.77kB/s]"
          }
        },
        "8bc34368480448bc82f5d8b0034e16fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f4311d97b43416ba95a2b52dfc5913a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e0e5ff517249d1927fcbaa3c0f0b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94dec1e92d0348ec8fe9ae31068f1606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d17b6f00b1b44d24af6315eaae00b1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "365a4e4a0611478f8b51179f32521caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "028a1261e460416bb4de2d695da73b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1315208aa6524b74acf38ef0bb666532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_781499f26ecc4596bc99ae66f2bfe7b0",
              "IPY_MODEL_4da63f02b0164415946bbf49c13e97d0",
              "IPY_MODEL_dea1380d55e14d71895b0819a6efdec0"
            ],
            "layout": "IPY_MODEL_4b2f9c4d01c34f129b9cb9277e0ff74d"
          }
        },
        "781499f26ecc4596bc99ae66f2bfe7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6e4695deb754d3b90958b14f20fd0dc",
            "placeholder": "​",
            "style": "IPY_MODEL_cd96010d967442e7a3bfed924198cde3",
            "value": "Generating test split: 100%"
          }
        },
        "4da63f02b0164415946bbf49c13e97d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8d35554c1944f0bbe0b8fa563ab382b",
            "max": 378,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee17bcdc0d0e4f3e92d15c4291f30909",
            "value": 378
          }
        },
        "dea1380d55e14d71895b0819a6efdec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9726e85c5f98439a911704bf1bce5699",
            "placeholder": "​",
            "style": "IPY_MODEL_6d4e3599ffa04c8893283ba8cb8c8337",
            "value": " 378/378 [00:00&lt;00:00, 9633.11 examples/s]"
          }
        },
        "4b2f9c4d01c34f129b9cb9277e0ff74d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e4695deb754d3b90958b14f20fd0dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd96010d967442e7a3bfed924198cde3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8d35554c1944f0bbe0b8fa563ab382b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee17bcdc0d0e4f3e92d15c4291f30909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9726e85c5f98439a911704bf1bce5699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d4e3599ffa04c8893283ba8cb8c8337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f667567100654c48895ae28747bc3084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa2cd12a95564b1ab21b8762423dd592",
              "IPY_MODEL_5c514f8a122e4fd88838e4bd2ac98456",
              "IPY_MODEL_ff697d0610ff48028c2e871dc73e9a53"
            ],
            "layout": "IPY_MODEL_fc263eba07b444c087b83689eff2025a"
          }
        },
        "fa2cd12a95564b1ab21b8762423dd592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cf8d3a902a3418f85725fc581f40be8",
            "placeholder": "​",
            "style": "IPY_MODEL_a98ef56855464be995cd85c5fdf7d1fd",
            "value": "Generating validation split: 100%"
          }
        },
        "5c514f8a122e4fd88838e4bd2ac98456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9a81b90e9c34dd8a0d815a9840d53fd",
            "max": 41,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af4abd5c05ff43189ec60ab4ff7782d8",
            "value": 41
          }
        },
        "ff697d0610ff48028c2e871dc73e9a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01c9d7c11fd8417b8126c173733b7a65",
            "placeholder": "​",
            "style": "IPY_MODEL_2de034682fdc4216a623122f905e90f3",
            "value": " 41/41 [00:00&lt;00:00, 3430.75 examples/s]"
          }
        },
        "fc263eba07b444c087b83689eff2025a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf8d3a902a3418f85725fc581f40be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98ef56855464be995cd85c5fdf7d1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9a81b90e9c34dd8a0d815a9840d53fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4abd5c05ff43189ec60ab4ff7782d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01c9d7c11fd8417b8126c173733b7a65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2de034682fdc4216a623122f905e90f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dc6e5519db749f98ed15e74b42eff91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_493869e840bb41f08c3dc50701159893",
              "IPY_MODEL_39c0105ad57e4f49b826dd3020a8179f",
              "IPY_MODEL_f77d62e5af884680a0728b2a0216eb1b"
            ],
            "layout": "IPY_MODEL_91770eca05294ccb93c681e4c865ea88"
          }
        },
        "493869e840bb41f08c3dc50701159893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12696b0c8df74f55adb60faf0e6a39ae",
            "placeholder": "​",
            "style": "IPY_MODEL_7a8bc2c74e334dac94bf235fcd5c6507",
            "value": "Generating dev split: 100%"
          }
        },
        "39c0105ad57e4f49b826dd3020a8179f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21143f7e6c7f47f2bf9649d3844b91d9",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26c2d5c8d0bd454f900bc3bd839dde84",
            "value": 5
          }
        },
        "f77d62e5af884680a0728b2a0216eb1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fca2a34f9fd4580bd0bf16daf0a07e9",
            "placeholder": "​",
            "style": "IPY_MODEL_132584fba34b4fb99cd500aa0bdfb7b7",
            "value": " 5/5 [00:00&lt;00:00, 437.60 examples/s]"
          }
        },
        "91770eca05294ccb93c681e4c865ea88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12696b0c8df74f55adb60faf0e6a39ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8bc2c74e334dac94bf235fcd5c6507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21143f7e6c7f47f2bf9649d3844b91d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26c2d5c8d0bd454f900bc3bd839dde84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fca2a34f9fd4580bd0bf16daf0a07e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "132584fba34b4fb99cd500aa0bdfb7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}