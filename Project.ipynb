{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3676cc86fe504d38bc0bdd498cdc4455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa3c322550ef406e984d6329bc2374db",
              "IPY_MODEL_67136332fd63472688d6f9f40b73503b",
              "IPY_MODEL_4b50b1afa0c44951aebd3ab2aeffc5dc"
            ],
            "layout": "IPY_MODEL_445763c090034871adb9c894fa779f78"
          }
        },
        "fa3c322550ef406e984d6329bc2374db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aff200fbe6744a7a9af008b6e9d2a98e",
            "placeholder": "​",
            "style": "IPY_MODEL_f5112e4e8f1e4fa983e8904368cf5725",
            "value": "config.json: 100%"
          }
        },
        "67136332fd63472688d6f9f40b73503b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a702c02054424c1aaec6c1ccda9393e9",
            "max": 659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_214d7ff51c45420197fcaa3dbaf62ccf",
            "value": 659
          }
        },
        "4b50b1afa0c44951aebd3ab2aeffc5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a66481d2cb0413b9f890c5f7afed051",
            "placeholder": "​",
            "style": "IPY_MODEL_7ed05562f56843ca9428f9a8d7a504e5",
            "value": " 659/659 [00:00&lt;00:00, 105kB/s]"
          }
        },
        "445763c090034871adb9c894fa779f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff200fbe6744a7a9af008b6e9d2a98e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5112e4e8f1e4fa983e8904368cf5725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a702c02054424c1aaec6c1ccda9393e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "214d7ff51c45420197fcaa3dbaf62ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a66481d2cb0413b9f890c5f7afed051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed05562f56843ca9428f9a8d7a504e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2083eb695e24863ae778b186abbee40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d30924119714482a088214af4bfdfc1",
              "IPY_MODEL_da1c65429ae740f480c92eed2bfae0a8",
              "IPY_MODEL_2da76e76e60f4ba9adaddbb3b40e4c60"
            ],
            "layout": "IPY_MODEL_9b81f271605a4e63bb45ea66568a97ad"
          }
        },
        "7d30924119714482a088214af4bfdfc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbb76774afef4eebaa12bbb712530df9",
            "placeholder": "​",
            "style": "IPY_MODEL_e7c94fc50f0c4f8290db7cc1525eb3a2",
            "value": "model.safetensors: 100%"
          }
        },
        "da1c65429ae740f480c92eed2bfae0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a331e7f9dea94ab0a650134fdc9ce1aa",
            "max": 988097824,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b93012a946af4d7a8fd556e294dc2835",
            "value": 988097824
          }
        },
        "2da76e76e60f4ba9adaddbb3b40e4c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e865f208e4c489ca863c53bbba3d0f9",
            "placeholder": "​",
            "style": "IPY_MODEL_067e761f7d244d64a0924dc97a2bede8",
            "value": " 988M/988M [00:02&lt;00:00, 399MB/s]"
          }
        },
        "9b81f271605a4e63bb45ea66568a97ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbb76774afef4eebaa12bbb712530df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c94fc50f0c4f8290db7cc1525eb3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a331e7f9dea94ab0a650134fdc9ce1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b93012a946af4d7a8fd556e294dc2835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e865f208e4c489ca863c53bbba3d0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "067e761f7d244d64a0924dc97a2bede8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d6e25fe4c6140309d6a7e2fbd33499a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2417faa53b264d30a19cec1e72aa9906",
              "IPY_MODEL_8560b34244dd420c9fed725eab0831dd",
              "IPY_MODEL_3da853ec0218487088c7c0737de73c33"
            ],
            "layout": "IPY_MODEL_c34079f8e1044caa9ef5ad05fcb8d1ce"
          }
        },
        "2417faa53b264d30a19cec1e72aa9906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_364df49ef2ec455ba67a3941778f0260",
            "placeholder": "​",
            "style": "IPY_MODEL_78c0c86aee754752858fbd41c15e8266",
            "value": "generation_config.json: 100%"
          }
        },
        "8560b34244dd420c9fed725eab0831dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_296c9251d45c48e4b3d08a08242cc215",
            "max": 242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93852bd19fae42cab201e1afdd36a952",
            "value": 242
          }
        },
        "3da853ec0218487088c7c0737de73c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43be06904bea4a1e968736da99540e79",
            "placeholder": "​",
            "style": "IPY_MODEL_7d65acd91e25434290e037e50b75e736",
            "value": " 242/242 [00:00&lt;00:00, 27.7kB/s]"
          }
        },
        "c34079f8e1044caa9ef5ad05fcb8d1ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364df49ef2ec455ba67a3941778f0260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78c0c86aee754752858fbd41c15e8266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "296c9251d45c48e4b3d08a08242cc215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93852bd19fae42cab201e1afdd36a952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43be06904bea4a1e968736da99540e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d65acd91e25434290e037e50b75e736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6df07453d9847f8a8e79896863d7ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d77815222ec84df1a365276953dbd406",
              "IPY_MODEL_2a0bc4afe938405582a4306430c277a1",
              "IPY_MODEL_12f0408e3fce435eb5262ef17f7fc1be"
            ],
            "layout": "IPY_MODEL_61a7b20f5932430eb059ea9d1564cd94"
          }
        },
        "d77815222ec84df1a365276953dbd406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7217c019f64584a0f829385289cf3e",
            "placeholder": "​",
            "style": "IPY_MODEL_00325eb5a70046b8a61625f76979dbe0",
            "value": "Tokenizing: 100%"
          }
        },
        "2a0bc4afe938405582a4306430c277a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_690c4b1134ed43dd9fc71ccacb89f054",
            "max": 128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e70dc7414f440e78270b8554fdba9e5",
            "value": 128
          }
        },
        "12f0408e3fce435eb5262ef17f7fc1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b032ba0e3344534bbc410a0ceef086d",
            "placeholder": "​",
            "style": "IPY_MODEL_87f6a3880b85460a844eb2c0ed6de4b6",
            "value": " 128/128 [00:00&lt;00:00, 1204.61 examples/s]"
          }
        },
        "61a7b20f5932430eb059ea9d1564cd94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7217c019f64584a0f829385289cf3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00325eb5a70046b8a61625f76979dbe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "690c4b1134ed43dd9fc71ccacb89f054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e70dc7414f440e78270b8554fdba9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b032ba0e3344534bbc410a0ceef086d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f6a3880b85460a844eb2c0ed6de4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a47bae8096374216adec933f5a043cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_781594b3725143ed92f6a4442c80ded4",
              "IPY_MODEL_68baabbec4c94fa1807071db5a2eed15",
              "IPY_MODEL_4b89de34c4d249f68dc9ce159b30ed4f"
            ],
            "layout": "IPY_MODEL_31b53fb4e96f42ae921f8e0a50b0e2ec"
          }
        },
        "781594b3725143ed92f6a4442c80ded4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0968f69ce1548f397fa2069a4d99b01",
            "placeholder": "​",
            "style": "IPY_MODEL_6b0b122241da49f18d4b66eba4233a05",
            "value": "Tokenizing: 100%"
          }
        },
        "68baabbec4c94fa1807071db5a2eed15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece8bc9021734648b923cb329df3dbb4",
            "max": 128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8715d561d16540fdb31f1fbe0aa1db75",
            "value": 128
          }
        },
        "4b89de34c4d249f68dc9ce159b30ed4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_827144d59f1540b282415f1b741f4a93",
            "placeholder": "​",
            "style": "IPY_MODEL_5db6f96cd6e0475ab9f4a621e759a7ab",
            "value": " 128/128 [00:00&lt;00:00, 1258.87 examples/s]"
          }
        },
        "31b53fb4e96f42ae921f8e0a50b0e2ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0968f69ce1548f397fa2069a4d99b01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b0b122241da49f18d4b66eba4233a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ece8bc9021734648b923cb329df3dbb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8715d561d16540fdb31f1fbe0aa1db75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "827144d59f1540b282415f1b741f4a93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5db6f96cd6e0475ab9f4a621e759a7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall transformers torch torchaudio torchvision wandb -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFV9pEkECKxG",
        "outputId": "bc17e3dd-b5d8-410e-8b35-03492e96b24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.57.2\n",
            "Uninstalling transformers-4.57.2:\n",
            "  Successfully uninstalled transformers-4.57.2\n",
            "Found existing installation: torch 2.9.0+cu126\n",
            "Uninstalling torch-2.9.0+cu126:\n",
            "  Successfully uninstalled torch-2.9.0+cu126\n",
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Found existing installation: torchvision 0.24.0+cu126\n",
            "Uninstalling torchvision-0.24.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.24.0+cu126\n",
            "Found existing installation: wandb 0.23.0\n",
            "Uninstalling wandb-0.23.0:\n",
            "  Successfully uninstalled wandb-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install llmcompressor\n",
        "!pip install -q accelerate bitsandbytes datasets scipy matplotlib"
      ],
      "metadata": {
        "id": "JtGbCeeFWjZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wSMOqXqWgJJ",
        "outputId": "92b89295-c4cb-4b75-c404-075c9a9af02f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from datasets import Dataset\n",
        "import copy\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from transformers import AwqConfig\n",
        "import shutil\n",
        "from llmcompressor import oneshot\n",
        "from llmcompressor.modifiers.quantization import GPTQModifier\n",
        "from llmcompressor.modifiers.awq import AWQModifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from transformers import set_seed\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "set_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "E8tJpydOUJBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_RUN = True\n",
        "\n",
        "if TEST_RUN:\n",
        "  # Model & Data\n",
        "  MODEL_ID = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "  calib_dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
        "  calib_input = tokenizer(\"\\n\\n\".join(calib_dataset[\"text\"][:10]), return_tensors=\"pt\").input_ids[:, :512].to(device)\n",
        "\n",
        "  NUM_EVAL_SAMPLES = 200\n",
        "  MMLU_SUBSET = [\"elementary_mathematics\"]\n",
        "  list_of_datasets = [\n",
        "    load_dataset(\"cais/mmlu\", subset, split='test')\n",
        "    for subset in MMLU_SUBSET\n",
        "  ]\n",
        "  mmlu_dataset = concatenate_datasets(list_of_datasets)\n",
        "  results = {}\n",
        "else:\n",
        "  MODEL_ID = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "  mmlu_dataset = load_dataset(\"cais/mmlu\", split=\"test\")\n",
        "  results = {}"
      ],
      "metadata": {
        "id": "oETCNrNB-3Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions\n",
        "def compute_kld(logits_p, logits_q):\n",
        "    \"\"\"KL Divergence: P=Baseline, Q=Quantized\"\"\"\n",
        "    p_probs = F.softmax(logits_p, dim=-1)\n",
        "    q_log_probs = F.log_softmax(logits_q, dim=-1)\n",
        "    return nn.KLDivLoss(reduction='batchmean')(q_log_probs, p_probs).item()\n",
        "\n",
        "def format_mmlu_prompt(example):\n",
        "    options = [f\"{label}. {example['choices'][i]}\" for i, label in enumerate(['A', 'B', 'C', 'D'])]\n",
        "    prompt_text = f\"Question: {example['question']}\\nOptions:\\n\" + \"\\n\".join(options) + \"\\nAnswer:\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Output only the single letter (A, B, C, or D) corresponding to the correct answer.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_text}\n",
        "    ]\n",
        "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "def get_mmlu_predictions(model, dataset, num_samples):\n",
        "    predictions, ground_truths = [], []\n",
        "    choices = [\"A\", \"B\", \"C\", \"D\"]\n",
        "    choice_ids = [tokenizer.encode(c)[0] for c in choices]\n",
        "\n",
        "    print(f\"Evaluating {num_samples} samples...\")\n",
        "    for i in tqdm(range(num_samples)):\n",
        "        ex = dataset[i]\n",
        "        inputs = tokenizer(format_mmlu_prompt(ex), return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits[0, -1, choice_ids]\n",
        "            pred = choices[torch.argmax(logits).item()]\n",
        "        predictions.append(pred)\n",
        "        ground_truths.append(choices[ex['answer']])\n",
        "    return predictions, ground_truths\n",
        "\n",
        "def fake_quantize_tensor_rtn(w):\n",
        "    \"\"\"\n",
        "    Round-To-Nearest (RTN) simulation.\n",
        "    We ONLY use this for PROFILING sensitivity, not for the final model.\n",
        "    \"\"\"\n",
        "    bits = 4\n",
        "    max_val = w.abs().max()\n",
        "    scale = max_val / (2**(bits-1) - 1)\n",
        "    return (w / scale).round().clamp(-8, 7) * scale\n",
        "\n",
        "def eval_and_record(model, name):\n",
        "    preds, _ = get_mmlu_predictions(model, mmlu_dataset, NUM_EVAL_SAMPLES)\n",
        "    acc = sum([1 for p, g in zip(preds, ground_truths) if p == g]) / len(ground_truths)\n",
        "    flips = sum([1 for b, q in zip(base_preds, preds) if b != q])\n",
        "    rate = flips / len(base_preds)\n",
        "    results[name] = {\"Acc\": acc, \"Flip\": rate}\n",
        "    print(f\"{name} -> Acc: {acc:.2%}, Flip: {rate:.2%}\")"
      ],
      "metadata": {
        "id": "GobKy4ZhWudQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Profiling & Baseline (FP16)\n",
        "print(\"--- 1. Loading FP16 Model for Profiling ---\")\n",
        "model_fp16 = AutoModelForCausalLM.from_pretrained(MODEL_ID, dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "# A. Compute Baseline MMLU (Ground Truth for Flips)\n",
        "print(\"Computing FP16 Baseline predictions...\")\n",
        "base_preds, ground_truths = get_mmlu_predictions(model_fp16, mmlu_dataset, NUM_EVAL_SAMPLES)\n",
        "base_acc = sum([1 for p, g in zip(base_preds, ground_truths) if p == g]) / len(ground_truths)\n",
        "print(f\"Baseline Accuracy: {base_acc:.2%}\")\n",
        "\n",
        "results['FP16 Baseline'] = {'Acc': base_acc, 'Flip': 0.0}\n",
        "\n",
        "# B. Profile Sensitivity (Using RTN Proxy)\n",
        "# Note: We use RTN to *find* sensitive layers. We will use NF4 to *quantize* the others.\n",
        "print(\"Profiling Layer Sensitivity...\")\n",
        "with torch.no_grad():\n",
        "    base_logits = model_fp16(calib_input).logits\n",
        "\n",
        "linear_layers = {name: m for name, m in model_fp16.named_modules() if isinstance(m, nn.Linear)}\n",
        "sensitivity_scores = {}\n",
        "\n",
        "for name, layer in tqdm(linear_layers.items()):\n",
        "    original_weight = layer.weight.data.clone()\n",
        "    # Perturb with RTN\n",
        "    layer.weight.data = fake_quantize_tensor_rtn(original_weight)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        kld = compute_kld(base_logits, model_fp16(calib_input).logits)\n",
        "        sensitivity_scores[name] = kld\n",
        "\n",
        "    # Restore\n",
        "    layer.weight.data = original_weight\n",
        "\n",
        "# Identify Top 5% Sensitive Layers\n",
        "sorted_layers = sorted(sensitivity_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "KEEP_RATIO = 0.05\n",
        "sensitive_layer_names = set([n for n, s in sorted_layers[:int(len(sorted_layers)*KEEP_RATIO)]])\n",
        "print(f\"Identified {len(sensitive_layer_names)} sensitive layers to keep in FP16.\")\n",
        "\n",
        "# Important: We must KEEP model_fp16 in memory (or cpu) to extract weights later\n",
        "# Move to CPU to save GPU RAM for the next models\n",
        "model_fp16.cpu()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259,
          "referenced_widgets": [
            "3676cc86fe504d38bc0bdd498cdc4455",
            "fa3c322550ef406e984d6329bc2374db",
            "67136332fd63472688d6f9f40b73503b",
            "4b50b1afa0c44951aebd3ab2aeffc5dc",
            "445763c090034871adb9c894fa779f78",
            "aff200fbe6744a7a9af008b6e9d2a98e",
            "f5112e4e8f1e4fa983e8904368cf5725",
            "a702c02054424c1aaec6c1ccda9393e9",
            "214d7ff51c45420197fcaa3dbaf62ccf",
            "1a66481d2cb0413b9f890c5f7afed051",
            "7ed05562f56843ca9428f9a8d7a504e5",
            "e2083eb695e24863ae778b186abbee40",
            "7d30924119714482a088214af4bfdfc1",
            "da1c65429ae740f480c92eed2bfae0a8",
            "2da76e76e60f4ba9adaddbb3b40e4c60",
            "9b81f271605a4e63bb45ea66568a97ad",
            "cbb76774afef4eebaa12bbb712530df9",
            "e7c94fc50f0c4f8290db7cc1525eb3a2",
            "a331e7f9dea94ab0a650134fdc9ce1aa",
            "b93012a946af4d7a8fd556e294dc2835",
            "0e865f208e4c489ca863c53bbba3d0f9",
            "067e761f7d244d64a0924dc97a2bede8",
            "3d6e25fe4c6140309d6a7e2fbd33499a",
            "2417faa53b264d30a19cec1e72aa9906",
            "8560b34244dd420c9fed725eab0831dd",
            "3da853ec0218487088c7c0737de73c33",
            "c34079f8e1044caa9ef5ad05fcb8d1ce",
            "364df49ef2ec455ba67a3941778f0260",
            "78c0c86aee754752858fbd41c15e8266",
            "296c9251d45c48e4b3d08a08242cc215",
            "93852bd19fae42cab201e1afdd36a952",
            "43be06904bea4a1e968736da99540e79",
            "7d65acd91e25434290e037e50b75e736"
          ]
        },
        "id": "VMgnsLeIW4JT",
        "outputId": "a6330082-c1d2-43f1-9572-bab51f45ab99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Loading FP16 Model for Profiling ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3676cc86fe504d38bc0bdd498cdc4455"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2083eb695e24863ae778b186abbee40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d6e25fe4c6140309d6a7e2fbd33499a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing FP16 Baseline predictions...\n",
            "Evaluating 200 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:07<00:00, 26.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy: 25.00%\n",
            "Profiling Layer Sensitivity...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169/169 [00:09<00:00, 18.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified 8 sensitive layers to keep in FP16.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper: Recursive Attribute Access ---\n",
        "def recursive_getattr(obj, attr):\n",
        "    for part in attr.split('.'):\n",
        "        obj = getattr(obj, part)\n",
        "    return obj\n",
        "\n",
        "def recursive_setattr(obj, attr, val):\n",
        "    pre, _, post = attr.rpartition('.')\n",
        "    parent = recursive_getattr(obj, pre) if pre else obj\n",
        "    setattr(parent, post, val)\n",
        "\n",
        "# --- Helper: Surgery Function (Reusable) ---\n",
        "def perform_surgery(model, sensitive_names, fp16_model_cpu):\n",
        "    \"\"\"\n",
        "    Replaces the sensitive quantized layers in 'model' (GPU)\n",
        "    with the original FP16 layers from 'fp16_model_cpu' (CPU).\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    print(f\"Surgery: Replacing {len(sensitive_names)} Sensitive Layers with FP16...\")\n",
        "\n",
        "    for name in sensitive_names:\n",
        "        try:\n",
        "            # 1. Get original FP16 weight from CPU backup\n",
        "            original_layer = recursive_getattr(fp16_model_cpu, name)\n",
        "\n",
        "            # 2. Create new Linear layer on GPU\n",
        "            new_layer = nn.Linear(\n",
        "                in_features=original_layer.in_features,\n",
        "                out_features=original_layer.out_features,\n",
        "                bias=(original_layer.bias is not None)\n",
        "            )\n",
        "            new_layer.weight.data = original_layer.weight.data.to(model.device)\n",
        "            if original_layer.bias is not None:\n",
        "                new_layer.bias.data = original_layer.bias.data.to(model.device)\n",
        "\n",
        "            # 3. Swap into the quantized model\n",
        "            recursive_setattr(model, name, new_layer)\n",
        "            count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping layer {name}: {e}\")\n",
        "\n",
        "    print(f\"Surgery Complete: {count} layers restored.\")"
      ],
      "metadata": {
        "id": "rib8XpYV_5bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluation Pipeline ---\n",
        "# --- Prepare Calibration Data ---\n",
        "print(\"Preparing calibration data...\")\n",
        "if 'calib_dataset' in globals():\n",
        "    raw_calib_data = [text for text in calib_dataset[\"text\"] if len(text) > 0][:128]\n",
        "else:\n",
        "    from datasets import load_dataset\n",
        "    ds = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
        "    raw_calib_data = [text for text in ds[\"text\"] if len(text) > 0][:128]\n",
        "\n",
        "# ==========================================\n",
        "# 1. LLM.int8() Pair\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- 1. Evaluating LLM.int8 Pair ---\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "model_int8 = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID, load_in_8bit=True, device_map=\"auto\"\n",
        ")\n",
        "eval_and_record(model_int8, \"LLM.int8()\")\n",
        "\n",
        "# KLD Surgery\n",
        "perform_surgery(model_int8, sensitive_layer_names, model_fp16)\n",
        "eval_and_record(model_int8, \"KLD-LLM.int8()\")\n",
        "\n",
        "del model_int8\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVqvTK8ZSSIB",
        "outputId": "3dbd1ca9-9777-4130-8536-14b645e8c3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing calibration data...\n",
            "\n",
            "==================================================\n",
            "--- 1. Evaluating LLM.int8 Pair ---\n",
            "==================================================\n",
            "Evaluating 200 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:32<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM.int8() -> Acc: 26.00%, Flip: 19.00%\n",
            "Surgery: Replacing 8 Sensitive Layers with FP16...\n",
            "Surgery Complete: 8 layers restored.\n",
            "Evaluating 200 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:31<00:00,  6.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KLD-LLM.int8() -> Acc: 25.00%, Flip: 15.50%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 2. NF4 Pair\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- 2. Evaluating NF4 Pair ---\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "model_nf4 = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID, quantization_config=nf4_config, device_map=\"auto\"\n",
        ")\n",
        "eval_and_record(model_nf4, \"NF4 (Standard)\")\n",
        "\n",
        "# KLD Surgery\n",
        "perform_surgery(model_nf4, sensitive_layer_names, model_fp16)\n",
        "eval_and_record(model_nf4, \"KLD-NF4()\")\n",
        "\n",
        "del model_nf4\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARPyFPEASZYP",
        "outputId": "44f3beb5-7c43-4f48-997a-48bfbd8f8cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "--- 2. Evaluating NF4 Pair ---\n",
            "==================================================\n",
            "Evaluating 200 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:13<00:00, 14.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NF4 (Standard) -> Acc: 26.50%, Flip: 63.00%\n",
            "Surgery: Replacing 8 Sensitive Layers with FP16...\n",
            "Surgery Complete: 8 layers restored.\n",
            "Evaluating 200 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:12<00:00, 15.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KLD-NF4() -> Acc: 28.00%, Flip: 43.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3694"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 3. AWQ Pair (via llmcompressor)\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- 3. Evaluating AWQ Pair (llmcompressor) ---\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# llmcompressor expects a HF Dataset object\n",
        "calib_dataset_obj = Dataset.from_dict({\"text\": raw_calib_data})\n",
        "\n",
        "# Define Recipe for AWQ\n",
        "recipe_awq = [\n",
        "    AWQModifier(\n",
        "        targets=\"Linear\",\n",
        "        scheme=\"W4A16\"  # 4-bit weights, 16-bit activations\n",
        "        # Removed: start_step=0, as it's not a valid argument\n",
        "    )\n",
        "]\n",
        "\n",
        "# Run Oneshot Quantization\n",
        "# Note: llmcompressor handles loading the model internally for oneshot\n",
        "print(\"Running AWQ Quantization...\")\n",
        "oneshot(\n",
        "    model=MODEL_ID,\n",
        "    dataset=calib_dataset_obj,\n",
        "    recipe=recipe_awq,\n",
        "    output_dir=\"./awq_llmcompressor_temp\",\n",
        "    num_calibration_samples=len(raw_calib_data),\n",
        "    max_seq_length=512,\n",
        "    save_compressed=True\n",
        ")\n",
        "\n",
        "# Load the saved quantized model\n",
        "model_awq = AutoModelForCausalLM.from_pretrained(\n",
        "    \"./awq_llmcompressor_temp\", device_map=\"auto\", trust_remote_code=True\n",
        ")\n",
        "eval_and_record(model_awq, \"AWQ (Standard)\")\n",
        "\n",
        "# KLD Surgery\n",
        "perform_surgery(model_awq, sensitive_layer_names, model_fp16)\n",
        "eval_and_record(model_awq, \"KLD-AWQ()\")\n",
        "\n",
        "del model_awq\n",
        "shutil.rmtree(\"./awq_llmcompressor_temp\") # Clean up disk\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d6df07453d9847f8a8e79896863d7ad1",
            "d77815222ec84df1a365276953dbd406",
            "2a0bc4afe938405582a4306430c277a1",
            "12f0408e3fce435eb5262ef17f7fc1be",
            "61a7b20f5932430eb059ea9d1564cd94",
            "7d7217c019f64584a0f829385289cf3e",
            "00325eb5a70046b8a61625f76979dbe0",
            "690c4b1134ed43dd9fc71ccacb89f054",
            "3e70dc7414f440e78270b8554fdba9e5",
            "8b032ba0e3344534bbc410a0ceef086d",
            "87f6a3880b85460a844eb2c0ed6de4b6"
          ]
        },
        "id": "qWm3Lzv_NqE4",
        "outputId": "22245a07-493b-4f7a-b47b-172005797d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "--- 3. Evaluating AWQ Pair (llmcompressor) ---\n",
            "==================================================\n",
            "Running AWQ Quantization...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing:   0%|          | 0/128 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6df07453d9847f8a8e79896863d7ad1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:08:39.308441+0000 | reset | INFO - Compression lifecycle reset\n",
            "2025-12-02T23:08:39.316936+0000 | _create_default_logger | INFO - Logging all LLM Compressor modifier-level logs to sparse_logs/02-12-2025_23.08.39.log\n",
            "2025-12-02T23:08:39.318178+0000 | from_modifiers | INFO - Creating recipe from modifiers\n",
            "2025-12-02T23:08:39.347148+0000 | on_initialize | INFO - No AWQModifier.mappings provided, inferring from model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Resolving mapping 1/4 (0 skipped): : 24it [00:00, 1074.75it/s]\n",
            "Resolving mapping 2/4 (23 skipped): : 24it [00:00, 1698.96it/s]\n",
            "Resolving mapping 3/4 (0 skipped): : 24it [00:00, 1220.07it/s]\n",
            "Resolving mapping 4/4 (0 skipped): : 24it [00:00, 1603.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:08:39.428552+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n",
            "2025-12-02T23:08:39.429216+0000 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `AWQModifier`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Preparing cache: 100%|██████████| 128/128 [00:00<00:00, 294.12it/s]\n",
            "(1/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 64.95it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:23<00:00,  7.94s/it]\n",
            "(1/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 68.16it/s]\n",
            "(2/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 81.89it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:25<00:00,  8.37s/it]\n",
            "(2/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 124.34it/s]\n",
            "(3/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 91.68it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.24s/it]\n",
            "(3/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 127.33it/s]\n",
            "(4/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 94.13it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.11s/it]\n",
            "(4/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 126.26it/s]\n",
            "(5/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 92.77it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.24s/it]\n",
            "(5/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 125.34it/s]\n",
            "(6/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 93.59it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.28s/it]\n",
            "(6/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 126.48it/s]\n",
            "(7/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 94.37it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.19s/it]\n",
            "(7/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 126.34it/s]\n",
            "(8/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 92.85it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.20s/it]\n",
            "(8/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 124.45it/s]\n",
            "(9/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 95.72it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.25s/it]\n",
            "(9/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 125.87it/s]\n",
            "(10/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 92.45it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.21s/it]\n",
            "(10/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 126.05it/s]\n",
            "(11/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 91.13it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.20s/it]\n",
            "(11/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 126.79it/s]\n",
            "(12/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 94.81it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.23s/it]\n",
            "(12/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 126.31it/s]\n",
            "(13/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 92.39it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.25s/it]\n",
            "(13/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 125.70it/s]\n",
            "(14/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 88.32it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.23s/it]\n",
            "(14/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 124.87it/s]\n",
            "(15/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 91.41it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.19s/it]\n",
            "(15/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 125.92it/s]\n",
            "(16/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 91.92it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.22s/it]\n",
            "(16/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 124.97it/s]\n",
            "(17/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 86.01it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.24s/it]\n",
            "(17/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 125.79it/s]\n",
            "(18/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 91.65it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.22s/it]\n",
            "(18/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 125.73it/s]\n",
            "(19/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 90.94it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.21s/it]\n",
            "(19/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 125.92it/s]\n",
            "(20/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 93.91it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.22s/it]\n",
            "(20/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 125.91it/s]\n",
            "(21/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 98.10it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.23s/it]\n",
            "(21/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 126.64it/s]\n",
            "(22/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 98.47it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.23s/it]\n",
            "(22/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 125.98it/s]\n",
            "(23/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 98.10it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.25s/it]\n",
            "(23/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 126.56it/s]\n",
            "(24/25): Calibrating: 100%|██████████| 128/128 [00:01<00:00, 98.19it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [00:24<00:00,  8.21s/it]\n",
            "(24/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 126.45it/s]\n",
            "(25/25): Calibrating: 100%|██████████| 128/128 [00:08<00:00, 15.98it/s]\n",
            "Smoothing: 0it [00:00, ?it/s]\n",
            "(25/25): Propagating: 100%|██████████| 128/128 [00:08<00:00, 15.98it/s]\n",
            "Smoothing: 0it [00:00, ?it/s]\n",
            "Calibrating weights: 169it [00:01, 145.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:19:49.745712+0000 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n",
            "2025-12-02T23:19:49.788278+0000 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Compressing model: 169it [00:01, 104.29it/s]\n",
            "Compressing model: 169it [00:00, 1168.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating 200 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:24<00:00,  8.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AWQ (Standard) -> Acc: 29.50%, Flip: 79.00%\n",
            "Surgery: Replacing 8 Sensitive Layers with FP16...\n",
            "Surgery Complete: 8 layers restored.\n",
            "Evaluating 200 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:19<00:00, 10.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KLD-AWQ() -> Acc: 20.50%, Flip: 42.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7848"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. GPTQ Pair (via llmcompressor)\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- 4. Evaluating GPTQ Pair (llmcompressor) ---\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Define Recipe for GPTQ\n",
        "recipe_gptq = [\n",
        "    GPTQModifier(\n",
        "        targets=\"Linear\",\n",
        "        scheme=\"W4A16\",\n",
        "        ignore=[\"lm_head\"],\n",
        "        dampening_frac=0.01  # Standard value\n",
        "    )\n",
        "]\n",
        "\n",
        "# Run Oneshot Quantization\n",
        "print(\"Running GPTQ Quantization...\")\n",
        "oneshot(\n",
        "    model=MODEL_ID,\n",
        "    dataset=calib_dataset_obj,\n",
        "    recipe=recipe_gptq,\n",
        "    output_dir=\"./gptq_llmcompressor_temp\",\n",
        "    num_calibration_samples=len(raw_calib_data),\n",
        "    max_seq_length=512,\n",
        "    save_compressed=True\n",
        ")\n",
        "\n",
        "# Load the saved quantized model\n",
        "model_gptq = AutoModelForCausalLM.from_pretrained(\n",
        "    \"./gptq_llmcompressor_temp\", device_map=\"auto\", trust_remote_code=True\n",
        ")\n",
        "eval_and_record(model_gptq, \"GPTQ (Standard)\")\n",
        "\n",
        "# KLD Surgery\n",
        "perform_surgery(model_gptq, sensitive_layer_names, model_fp16)\n",
        "eval_and_record(model_gptq, \"KLD-GPTQ()\")\n",
        "\n",
        "del model_gptq\n",
        "shutil.rmtree(\"./gptq_llmcompressor_temp\")\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a47bae8096374216adec933f5a043cd6",
            "781594b3725143ed92f6a4442c80ded4",
            "68baabbec4c94fa1807071db5a2eed15",
            "4b89de34c4d249f68dc9ce159b30ed4f",
            "31b53fb4e96f42ae921f8e0a50b0e2ec",
            "e0968f69ce1548f397fa2069a4d99b01",
            "6b0b122241da49f18d4b66eba4233a05",
            "ece8bc9021734648b923cb329df3dbb4",
            "8715d561d16540fdb31f1fbe0aa1db75",
            "827144d59f1540b282415f1b741f4a93",
            "5db6f96cd6e0475ab9f4a621e759a7ab"
          ]
        },
        "id": "7JLK57rKQ3GO",
        "outputId": "744a507a-5c2a-4876-d362-8c521a881467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "--- 4. Evaluating GPTQ Pair (llmcompressor) ---\n",
            "==================================================\n",
            "Running GPTQ Quantization...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing:   0%|          | 0/128 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a47bae8096374216adec933f5a043cd6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:20:40.487947+0000 | reset | INFO - Compression lifecycle reset\n",
            "2025-12-02T23:20:40.490465+0000 | from_modifiers | INFO - Creating recipe from modifiers\n",
            "2025-12-02T23:20:40.521637+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n",
            "2025-12-02T23:20:40.522375+0000 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `GPTQModifier`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preparing cache: 100%|██████████| 128/128 [00:00<00:00, 253.82it/s]\n",
            "(1/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 47.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:20:44.301423+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:20:44.861000+0000 | compress | METRIC - time 0.56s\n",
            "2025-12-02T23:20:44.862244+0000 | compress | METRIC - error 22.05\n",
            "2025-12-02T23:20:44.863665+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:44.864359+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:20:44.865582+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:20:45.372110+0000 | compress | METRIC - time 0.51s\n",
            "2025-12-02T23:20:45.373319+0000 | compress | METRIC - error 3.37\n",
            "2025-12-02T23:20:45.374414+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:45.375495+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:20:45.376429+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:20:45.860937+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:20:45.861886+0000 | compress | METRIC - error 0.08\n",
            "2025-12-02T23:20:45.862435+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:45.863446+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:20:45.864515+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:20:46.327897+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:20:46.329213+0000 | compress | METRIC - error 0.04\n",
            "2025-12-02T23:20:46.329962+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:46.330599+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:20:46.331654+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:20:46.860618+0000 | compress | METRIC - time 0.53s\n",
            "2025-12-02T23:20:46.861710+0000 | compress | METRIC - error 618.32\n",
            "2025-12-02T23:20:46.862674+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:46.863715+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:20:46.864644+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:20:47.365442+0000 | compress | METRIC - time 0.50s\n",
            "2025-12-02T23:20:47.366482+0000 | compress | METRIC - error 393.95\n",
            "2025-12-02T23:20:47.367327+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:47.368169+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:20:47.369176+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:20:50.088384+0000 | compress | METRIC - time 2.72s\n",
            "2025-12-02T23:20:50.089396+0000 | compress | METRIC - error 5.59\n",
            "2025-12-02T23:20:50.090077+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:50.090777+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(1/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 71.50it/s]\n",
            "(2/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 56.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:20:54.351328+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:20:54.842572+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:20:54.843629+0000 | compress | METRIC - error 147.03\n",
            "2025-12-02T23:20:54.844379+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:54.844987+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:20:54.846225+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:20:55.307289+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:20:55.308355+0000 | compress | METRIC - error 41.03\n",
            "2025-12-02T23:20:55.309266+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:55.310074+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:20:55.311003+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:20:55.768613+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:20:55.769849+0000 | compress | METRIC - error 4.58\n",
            "2025-12-02T23:20:55.770515+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:55.771330+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:20:55.772365+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:20:56.245879+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:20:56.246890+0000 | compress | METRIC - error 3.15\n",
            "2025-12-02T23:20:56.247664+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:56.248396+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:20:56.249359+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:20:56.737870+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:20:56.739255+0000 | compress | METRIC - error 1315.42\n",
            "2025-12-02T23:20:56.740163+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:56.741150+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:20:56.742247+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:20:57.242998+0000 | compress | METRIC - time 0.50s\n",
            "2025-12-02T23:20:57.244211+0000 | compress | METRIC - error 686.01\n",
            "2025-12-02T23:20:57.245252+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:57.246046+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:20:57.247185+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:20:59.926180+0000 | compress | METRIC - time 2.68s\n",
            "2025-12-02T23:20:59.928864+0000 | compress | METRIC - error 7.92\n",
            "2025-12-02T23:20:59.929564+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:20:59.930334+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(2/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 116.08it/s]\n",
            "(3/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 56.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:03.327660+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:03.812928+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:21:03.814260+0000 | compress | METRIC - error 351.48\n",
            "2025-12-02T23:21:03.815006+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:03.815695+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:21:03.816841+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:21:04.270077+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:21:04.271130+0000 | compress | METRIC - error 96.04\n",
            "2025-12-02T23:21:04.271981+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:04.272720+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:04.273818+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:21:04.748979+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:21:04.750465+0000 | compress | METRIC - error 12.97\n",
            "2025-12-02T23:21:04.751494+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:04.752202+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:04.753360+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:21:05.217409+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:05.218841+0000 | compress | METRIC - error 3.53\n",
            "2025-12-02T23:21:05.219810+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:05.220801+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:21:05.221958+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:21:05.734176+0000 | compress | METRIC - time 0.51s\n",
            "2025-12-02T23:21:05.735487+0000 | compress | METRIC - error 1875.18\n",
            "2025-12-02T23:21:05.736834+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:05.737560+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:05.738767+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:21:06.233657+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:21:06.235119+0000 | compress | METRIC - error 1016.04\n",
            "2025-12-02T23:21:06.236042+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:06.236925+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:06.237806+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:21:08.898407+0000 | compress | METRIC - time 2.66s\n",
            "2025-12-02T23:21:08.901434+0000 | compress | METRIC - error 1462.95\n",
            "2025-12-02T23:21:08.902251+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:08.903118+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(3/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 120.14it/s]\n",
            "(4/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 54.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:12.321511+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:12.804671+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:21:12.806153+0000 | compress | METRIC - error 462.19\n",
            "2025-12-02T23:21:12.807087+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:12.807940+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:21:12.808967+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:21:13.269901+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:13.271150+0000 | compress | METRIC - error 109.44\n",
            "2025-12-02T23:21:13.271813+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:13.272801+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:13.273843+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:21:13.739717+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:21:13.740894+0000 | compress | METRIC - error 27.24\n",
            "2025-12-02T23:21:13.741577+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:13.742100+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:13.743234+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:21:14.198511+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:21:14.199748+0000 | compress | METRIC - error 2.60\n",
            "2025-12-02T23:21:14.200573+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:14.201162+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:21:14.202337+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:21:14.678458+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:21:14.679618+0000 | compress | METRIC - error 6277.72\n",
            "2025-12-02T23:21:14.680492+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:14.681172+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:14.682476+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:21:15.169133+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:21:15.170198+0000 | compress | METRIC - error 3433.55\n",
            "2025-12-02T23:21:15.171013+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:15.171817+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:15.172923+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:21:17.977438+0000 | compress | METRIC - time 2.80s\n",
            "2025-12-02T23:21:17.980363+0000 | compress | METRIC - error 545.18\n",
            "2025-12-02T23:21:17.981255+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:17.982151+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(4/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 118.58it/s]\n",
            "(5/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 53.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:21.493840+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:21.969583+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:21:21.970786+0000 | compress | METRIC - error 401.26\n",
            "2025-12-02T23:21:21.971517+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:21.972385+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:21:21.973610+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:21:22.438379+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:22.439784+0000 | compress | METRIC - error 80.10\n",
            "2025-12-02T23:21:22.440669+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:22.441620+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:22.442458+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:21:22.894300+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:21:22.895427+0000 | compress | METRIC - error 37.17\n",
            "2025-12-02T23:21:22.896086+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:22.897030+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:22.898010+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:21:23.363656+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:23.364932+0000 | compress | METRIC - error 6.80\n",
            "2025-12-02T23:21:23.365745+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:23.366554+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:21:23.367821+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:21:23.848355+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:21:23.849539+0000 | compress | METRIC - error 2727.83\n",
            "2025-12-02T23:21:23.850311+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:23.850948+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:23.852069+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:21:24.337966+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:21:24.339130+0000 | compress | METRIC - error 1793.88\n",
            "2025-12-02T23:21:24.339869+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:24.340644+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:24.341601+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:21:27.008952+0000 | compress | METRIC - time 2.67s\n",
            "2025-12-02T23:21:27.011901+0000 | compress | METRIC - error 37.64\n",
            "2025-12-02T23:21:27.012585+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:27.013338+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(5/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 118.43it/s]\n",
            "(6/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 51.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:30.612281+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:31.096272+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:21:31.097689+0000 | compress | METRIC - error 523.95\n",
            "2025-12-02T23:21:31.098593+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:31.099581+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:21:31.100494+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:21:31.559228+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:31.560546+0000 | compress | METRIC - error 104.69\n",
            "2025-12-02T23:21:31.561277+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:31.561896+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:31.562837+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:21:32.020147+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:32.021446+0000 | compress | METRIC - error 51.70\n",
            "2025-12-02T23:21:32.022141+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:32.022840+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:32.023850+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:21:32.483501+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:32.484823+0000 | compress | METRIC - error 6.43\n",
            "2025-12-02T23:21:32.485595+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:32.486248+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:21:32.487463+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:21:32.961693+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:21:32.963088+0000 | compress | METRIC - error 4505.56\n",
            "2025-12-02T23:21:32.963869+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:32.964814+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:32.965815+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:21:33.447990+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:21:33.449166+0000 | compress | METRIC - error 2294.16\n",
            "2025-12-02T23:21:33.450098+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:33.451025+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:33.451992+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:21:36.142637+0000 | compress | METRIC - time 2.69s\n",
            "2025-12-02T23:21:36.145438+0000 | compress | METRIC - error 44.22\n",
            "2025-12-02T23:21:36.146306+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:36.146990+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(6/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 114.26it/s]\n",
            "(7/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 50.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:39.836405+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:40.356355+0000 | compress | METRIC - time 0.52s\n",
            "2025-12-02T23:21:40.358097+0000 | compress | METRIC - error 481.02\n",
            "2025-12-02T23:21:40.359336+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:40.360273+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:21:40.361167+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:21:40.823587+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:40.824971+0000 | compress | METRIC - error 109.29\n",
            "2025-12-02T23:21:40.825690+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:40.826608+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:40.827577+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:21:41.279841+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:21:41.281033+0000 | compress | METRIC - error 31.90\n",
            "2025-12-02T23:21:41.281984+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:41.282905+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:41.283948+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:21:41.744818+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:41.746019+0000 | compress | METRIC - error 5.09\n",
            "2025-12-02T23:21:41.746779+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:41.747524+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:21:41.748558+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:21:42.226098+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:21:42.227199+0000 | compress | METRIC - error 3090.42\n",
            "2025-12-02T23:21:42.228107+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:42.228894+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:42.230339+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:21:42.706080+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:21:42.707337+0000 | compress | METRIC - error 2151.64\n",
            "2025-12-02T23:21:42.707987+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:42.708841+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:42.710054+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:21:45.387368+0000 | compress | METRIC - time 2.68s\n",
            "2025-12-02T23:21:45.390159+0000 | compress | METRIC - error 50.82\n",
            "2025-12-02T23:21:45.390836+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:45.391826+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(7/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 115.58it/s]\n",
            "(8/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 50.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:49.037945+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:49.508811+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:21:49.510097+0000 | compress | METRIC - error 661.70\n",
            "2025-12-02T23:21:49.510828+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:49.511489+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:21:49.512622+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:21:49.972743+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:49.974080+0000 | compress | METRIC - error 162.49\n",
            "2025-12-02T23:21:49.974684+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:49.975689+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:49.976886+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:21:50.439103+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:50.440543+0000 | compress | METRIC - error 53.53\n",
            "2025-12-02T23:21:50.441529+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:50.442553+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:50.443595+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:21:50.912402+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:21:50.913651+0000 | compress | METRIC - error 9.44\n",
            "2025-12-02T23:21:50.914543+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:50.915243+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:21:50.916391+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:21:51.397752+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:21:51.399029+0000 | compress | METRIC - error 3157.45\n",
            "2025-12-02T23:21:51.399879+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:51.400525+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:51.401946+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:21:51.899053+0000 | compress | METRIC - time 0.50s\n",
            "2025-12-02T23:21:51.900197+0000 | compress | METRIC - error 2467.78\n",
            "2025-12-02T23:21:51.900988+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:51.901547+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:21:51.902864+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:21:54.596001+0000 | compress | METRIC - time 2.69s\n",
            "2025-12-02T23:21:54.599044+0000 | compress | METRIC - error 81.92\n",
            "2025-12-02T23:21:54.599919+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:54.600536+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(8/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 119.11it/s]\n",
            "(9/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 51.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:58.178976+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:21:58.653489+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:21:58.654591+0000 | compress | METRIC - error 728.41\n",
            "2025-12-02T23:21:58.655670+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:58.656479+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:21:58.657635+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:21:59.122727+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:59.124047+0000 | compress | METRIC - error 134.15\n",
            "2025-12-02T23:21:59.124913+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:59.125960+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:59.127029+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:21:59.586536+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:21:59.587541+0000 | compress | METRIC - error 49.00\n",
            "2025-12-02T23:21:59.588307+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:21:59.589043+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:21:59.590101+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:22:00.051058+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:00.052325+0000 | compress | METRIC - error 19.90\n",
            "2025-12-02T23:22:00.052989+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:00.053648+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:22:00.054632+0000 | compress_modules | INFO - Quantizing model.layers.8.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:22:00.531561+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:22:00.532693+0000 | compress | METRIC - error 2512.80\n",
            "2025-12-02T23:22:00.533490+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:00.534158+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:00.535289+0000 | compress_modules | INFO - Quantizing model.layers.8.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:22:01.011839+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:22:01.012942+0000 | compress | METRIC - error 1941.08\n",
            "2025-12-02T23:22:01.013691+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:01.014502+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:01.015467+0000 | compress_modules | INFO - Quantizing model.layers.8.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:22:03.709197+0000 | compress | METRIC - time 2.69s\n",
            "2025-12-02T23:22:03.712529+0000 | compress | METRIC - error 38.92\n",
            "2025-12-02T23:22:03.713482+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:03.714374+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(9/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 116.74it/s]\n",
            "(10/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 53.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:07.205816+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:07.672943+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:22:07.673988+0000 | compress | METRIC - error 1282.41\n",
            "2025-12-02T23:22:07.674974+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:07.675889+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:22:07.676765+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:22:08.134754+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:08.135922+0000 | compress | METRIC - error 310.98\n",
            "2025-12-02T23:22:08.136765+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:08.137602+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:08.138749+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:22:08.597557+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:08.598752+0000 | compress | METRIC - error 90.19\n",
            "2025-12-02T23:22:08.599558+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:08.600156+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:08.601487+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:22:09.065685+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:09.067057+0000 | compress | METRIC - error 8.69\n",
            "2025-12-02T23:22:09.067951+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:09.068827+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:22:09.069816+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:22:09.552034+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:22:09.553196+0000 | compress | METRIC - error 2400.31\n",
            "2025-12-02T23:22:09.554078+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:09.554920+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:09.555932+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:22:10.029605+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:22:10.030614+0000 | compress | METRIC - error 2065.29\n",
            "2025-12-02T23:22:10.031429+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:10.032218+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:10.033145+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:22:12.694979+0000 | compress | METRIC - time 2.66s\n",
            "2025-12-02T23:22:12.697841+0000 | compress | METRIC - error 42.39\n",
            "2025-12-02T23:22:12.698516+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:12.699111+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(10/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 119.83it/s]\n",
            "(11/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 54.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:16.131660+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:16.609396+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:22:16.610698+0000 | compress | METRIC - error 609.65\n",
            "2025-12-02T23:22:16.611533+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:16.612365+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:22:16.613409+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:22:17.069879+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:17.071247+0000 | compress | METRIC - error 115.30\n",
            "2025-12-02T23:22:17.072046+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:17.072966+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:17.073953+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:22:17.530523+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:17.531776+0000 | compress | METRIC - error 85.17\n",
            "2025-12-02T23:22:17.532538+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:17.533076+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:17.534017+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:22:17.994026+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:17.995505+0000 | compress | METRIC - error 16.46\n",
            "2025-12-02T23:22:17.996330+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:17.997155+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:22:17.998037+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:22:18.471159+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:22:18.472449+0000 | compress | METRIC - error 2363.33\n",
            "2025-12-02T23:22:18.473282+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:18.474016+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:18.475060+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:22:18.979132+0000 | compress | METRIC - time 0.50s\n",
            "2025-12-02T23:22:18.980619+0000 | compress | METRIC - error 1844.75\n",
            "2025-12-02T23:22:18.981514+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:18.982468+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:18.983421+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:22:21.671546+0000 | compress | METRIC - time 2.69s\n",
            "2025-12-02T23:22:21.674667+0000 | compress | METRIC - error 35.24\n",
            "2025-12-02T23:22:21.675320+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:21.676249+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(11/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 117.15it/s]\n",
            "(12/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 54.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:25.115179+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:25.595524+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:22:25.597025+0000 | compress | METRIC - error 1376.24\n",
            "2025-12-02T23:22:25.597823+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:25.598575+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:22:25.600056+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:22:26.068398+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:22:26.069608+0000 | compress | METRIC - error 359.11\n",
            "2025-12-02T23:22:26.070577+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:26.071457+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:26.072586+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:22:26.538851+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:22:26.540108+0000 | compress | METRIC - error 104.13\n",
            "2025-12-02T23:22:26.540833+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:26.541769+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:26.542852+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:22:27.004059+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:27.005518+0000 | compress | METRIC - error 8.20\n",
            "2025-12-02T23:22:27.006447+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:27.007273+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:22:27.008271+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:22:27.484140+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:22:27.485497+0000 | compress | METRIC - error 2232.33\n",
            "2025-12-02T23:22:27.486381+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:27.487245+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:27.488396+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:22:27.962605+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:22:27.963811+0000 | compress | METRIC - error 2062.95\n",
            "2025-12-02T23:22:27.964555+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:27.965399+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:27.966401+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:22:30.614031+0000 | compress | METRIC - time 2.65s\n",
            "2025-12-02T23:22:30.617291+0000 | compress | METRIC - error 48.63\n",
            "2025-12-02T23:22:30.618280+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:30.619037+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(12/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 119.70it/s]\n",
            "(13/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 54.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:34.074426+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:34.544237+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:22:34.545410+0000 | compress | METRIC - error 625.59\n",
            "2025-12-02T23:22:34.546443+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:34.547333+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:22:34.548234+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:22:35.002289+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:22:35.003622+0000 | compress | METRIC - error 112.15\n",
            "2025-12-02T23:22:35.004414+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:35.004877+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:35.005946+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:22:35.454335+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:22:35.455648+0000 | compress | METRIC - error 72.56\n",
            "2025-12-02T23:22:35.456286+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:35.456977+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:35.457981+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:22:35.917382+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:35.918679+0000 | compress | METRIC - error 17.61\n",
            "2025-12-02T23:22:35.919459+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:35.920283+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:22:35.921321+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:22:36.423740+0000 | compress | METRIC - time 0.50s\n",
            "2025-12-02T23:22:36.424974+0000 | compress | METRIC - error 2010.71\n",
            "2025-12-02T23:22:36.425859+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:36.426625+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:36.427721+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:22:36.916102+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:22:36.917329+0000 | compress | METRIC - error 1804.72\n",
            "2025-12-02T23:22:36.918140+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:36.918785+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:36.920195+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:22:39.590893+0000 | compress | METRIC - time 2.67s\n",
            "2025-12-02T23:22:39.594089+0000 | compress | METRIC - error 34.39\n",
            "2025-12-02T23:22:39.595024+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:39.595978+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(13/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 116.58it/s]\n",
            "(14/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 52.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:43.141588+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:43.612059+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:22:43.613174+0000 | compress | METRIC - error 983.81\n",
            "2025-12-02T23:22:43.614165+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:43.615039+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:22:43.616101+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:22:44.071765+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:22:44.072943+0000 | compress | METRIC - error 191.87\n",
            "2025-12-02T23:22:44.073647+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:44.074369+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:44.075428+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:22:44.539881+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:44.541035+0000 | compress | METRIC - error 81.45\n",
            "2025-12-02T23:22:44.541828+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:44.542519+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:44.543580+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:22:44.998092+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:22:44.999211+0000 | compress | METRIC - error 11.00\n",
            "2025-12-02T23:22:44.999883+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:45.000796+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:22:45.001649+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:22:45.489143+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:22:45.490448+0000 | compress | METRIC - error 2069.44\n",
            "2025-12-02T23:22:45.491267+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:45.492170+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:45.493112+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:22:45.969693+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:22:45.970805+0000 | compress | METRIC - error 2043.52\n",
            "2025-12-02T23:22:45.971492+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:45.972370+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:45.973440+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:22:48.633000+0000 | compress | METRIC - time 2.66s\n",
            "2025-12-02T23:22:48.636338+0000 | compress | METRIC - error 39.83\n",
            "2025-12-02T23:22:48.637322+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:48.638277+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(14/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 114.97it/s]\n",
            "(15/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 50.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:52.283691+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:22:52.756861+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:22:52.758293+0000 | compress | METRIC - error 866.61\n",
            "2025-12-02T23:22:52.759244+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:52.760026+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:22:52.761178+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:22:53.219233+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:53.220621+0000 | compress | METRIC - error 134.92\n",
            "2025-12-02T23:22:53.221428+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:53.222642+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:53.223885+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:22:53.686135+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:22:53.687412+0000 | compress | METRIC - error 123.46\n",
            "2025-12-02T23:22:53.688446+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:53.689441+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:22:53.690374+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:22:54.168806+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:22:54.170292+0000 | compress | METRIC - error 22.41\n",
            "2025-12-02T23:22:54.171150+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:54.171923+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:22:54.172864+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:22:54.651471+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:22:54.652752+0000 | compress | METRIC - error 2191.91\n",
            "2025-12-02T23:22:54.653571+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:54.654263+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:54.655263+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:22:55.137431+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:22:55.138666+0000 | compress | METRIC - error 1927.23\n",
            "2025-12-02T23:22:55.139438+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:55.139962+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:22:55.141019+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:22:57.829643+0000 | compress | METRIC - time 2.69s\n",
            "2025-12-02T23:22:57.832919+0000 | compress | METRIC - error 42.18\n",
            "2025-12-02T23:22:57.833636+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:22:57.834301+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(15/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 116.40it/s]\n",
            "(16/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 51.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:01.441969+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:01.923642+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:01.924860+0000 | compress | METRIC - error 728.94\n",
            "2025-12-02T23:23:01.925641+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:01.926369+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:23:01.927279+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:23:02.385905+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:23:02.387057+0000 | compress | METRIC - error 139.69\n",
            "2025-12-02T23:23:02.387772+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:02.388855+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:02.389910+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:23:02.850034+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:23:02.851418+0000 | compress | METRIC - error 98.27\n",
            "2025-12-02T23:23:02.852085+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:02.852752+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:02.853803+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:23:03.320163+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:23:03.321596+0000 | compress | METRIC - error 14.11\n",
            "2025-12-02T23:23:03.322533+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:03.323257+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:23:03.324277+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:23:03.803909+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:03.805268+0000 | compress | METRIC - error 2537.99\n",
            "2025-12-02T23:23:03.805922+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:03.806438+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:03.807625+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:23:04.294023+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:23:04.295289+0000 | compress | METRIC - error 2431.10\n",
            "2025-12-02T23:23:04.296094+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:04.296589+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:04.297809+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:23:06.939747+0000 | compress | METRIC - time 2.64s\n",
            "2025-12-02T23:23:06.942969+0000 | compress | METRIC - error 56.10\n",
            "2025-12-02T23:23:06.943917+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:06.944664+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(16/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 115.87it/s]\n",
            "(17/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 52.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:10.520394+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:11.015342+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:23:11.016626+0000 | compress | METRIC - error 1373.68\n",
            "2025-12-02T23:23:11.017581+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:23:11.018333+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:23:11.019457+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:23:11.476682+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:23:11.477877+0000 | compress | METRIC - error 237.98\n",
            "2025-12-02T23:23:11.479015+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:23:11.480061+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:11.481072+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:23:11.962304+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:11.963808+0000 | compress | METRIC - error 220.87\n",
            "2025-12-02T23:23:11.964699+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:23:11.965396+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:11.966565+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:23:12.427491+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:23:12.428921+0000 | compress | METRIC - error 14.98\n",
            "2025-12-02T23:23:12.429677+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:23:12.430481+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:23:12.431433+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:23:12.916927+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:12.918255+0000 | compress | METRIC - error 3588.49\n",
            "2025-12-02T23:23:12.918900+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:23:12.919722+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:12.920603+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:23:13.427287+0000 | compress | METRIC - time 0.51s\n",
            "2025-12-02T23:23:13.428593+0000 | compress | METRIC - error 2813.98\n",
            "2025-12-02T23:23:13.429659+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:23:13.430604+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:13.431657+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:23:16.115975+0000 | compress | METRIC - time 2.68s\n",
            "2025-12-02T23:23:16.119087+0000 | compress | METRIC - error 98.65\n",
            "2025-12-02T23:23:16.120029+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:23:16.120764+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(17/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 118.48it/s]\n",
            "(18/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 52.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:19.638539+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:20.115148+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:20.116588+0000 | compress | METRIC - error 983.04\n",
            "2025-12-02T23:23:20.117335+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:20.118375+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:23:20.119422+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:23:20.578006+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:23:20.579250+0000 | compress | METRIC - error 145.93\n",
            "2025-12-02T23:23:20.580076+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:20.580688+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:20.581769+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:23:21.041551+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:23:21.043101+0000 | compress | METRIC - error 145.92\n",
            "2025-12-02T23:23:21.044005+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:21.044902+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:21.045811+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:23:21.509841+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:23:21.511315+0000 | compress | METRIC - error 12.29\n",
            "2025-12-02T23:23:21.512191+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:21.513046+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:23:21.513972+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:23:22.005095+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:23:22.006355+0000 | compress | METRIC - error 4967.13\n",
            "2025-12-02T23:23:22.007248+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:22.007990+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:22.009221+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:23:22.502494+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:23:22.503954+0000 | compress | METRIC - error 3167.05\n",
            "2025-12-02T23:23:22.504838+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:22.505552+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:22.506690+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:23:25.185803+0000 | compress | METRIC - time 2.68s\n",
            "2025-12-02T23:23:25.189047+0000 | compress | METRIC - error 89.82\n",
            "2025-12-02T23:23:25.189966+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:25.190793+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(18/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 117.79it/s]\n",
            "(19/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 52.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:28.718966+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:29.191166+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:23:29.192606+0000 | compress | METRIC - error 988.10\n",
            "2025-12-02T23:23:29.193375+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:29.194083+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:23:29.195038+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:23:29.647752+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:23:29.649176+0000 | compress | METRIC - error 181.67\n",
            "2025-12-02T23:23:29.650087+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:29.650780+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:29.651816+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:23:30.107250+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:23:30.108655+0000 | compress | METRIC - error 141.54\n",
            "2025-12-02T23:23:30.109384+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:30.110083+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:30.111344+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:23:30.574940+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:23:30.576416+0000 | compress | METRIC - error 14.39\n",
            "2025-12-02T23:23:30.577346+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:30.578300+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:23:30.579314+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:23:31.063669+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:31.064911+0000 | compress | METRIC - error 3992.50\n",
            "2025-12-02T23:23:31.065659+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:31.066277+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:31.067203+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:23:31.551919+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:31.553174+0000 | compress | METRIC - error 3181.06\n",
            "2025-12-02T23:23:31.553917+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:31.554937+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:31.555848+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:23:34.253815+0000 | compress | METRIC - time 2.70s\n",
            "2025-12-02T23:23:34.257276+0000 | compress | METRIC - error 91.46\n",
            "2025-12-02T23:23:34.258415+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:34.259163+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(19/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 117.05it/s]\n",
            "(20/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 53.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:37.759717+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:38.241876+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:38.243241+0000 | compress | METRIC - error 863.23\n",
            "2025-12-02T23:23:38.244071+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:38.244916+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:23:38.245867+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:23:38.698861+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:23:38.700444+0000 | compress | METRIC - error 142.40\n",
            "2025-12-02T23:23:38.701268+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:38.702150+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:38.703083+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:23:39.154715+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:23:39.156184+0000 | compress | METRIC - error 129.21\n",
            "2025-12-02T23:23:39.157080+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:39.158025+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:39.158976+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:23:39.619635+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:23:39.620998+0000 | compress | METRIC - error 19.67\n",
            "2025-12-02T23:23:39.621704+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:39.622620+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:23:39.623681+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:23:40.102055+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:40.103325+0000 | compress | METRIC - error 5530.35\n",
            "2025-12-02T23:23:40.104079+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:40.104944+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:40.106065+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:23:40.596999+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:23:40.598259+0000 | compress | METRIC - error 4625.44\n",
            "2025-12-02T23:23:40.599051+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:40.599750+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:40.600979+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:23:43.251751+0000 | compress | METRIC - time 2.65s\n",
            "2025-12-02T23:23:43.254623+0000 | compress | METRIC - error 182.27\n",
            "2025-12-02T23:23:43.255742+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:43.256650+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(20/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 119.39it/s]\n",
            "(21/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 52.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:46.776628+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:47.256246+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:47.257543+0000 | compress | METRIC - error 1270.12\n",
            "2025-12-02T23:23:47.258286+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:47.259139+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:23:47.260100+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:23:47.713519+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:23:47.714882+0000 | compress | METRIC - error 182.46\n",
            "2025-12-02T23:23:47.715650+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:47.716827+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:47.717698+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:23:48.166146+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:23:48.167482+0000 | compress | METRIC - error 427.49\n",
            "2025-12-02T23:23:48.168112+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:48.168671+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:48.169859+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:23:48.622271+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:23:48.623488+0000 | compress | METRIC - error 36.06\n",
            "2025-12-02T23:23:48.624561+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:48.625255+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:23:48.626372+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:23:49.103701+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:49.105172+0000 | compress | METRIC - error 5619.84\n",
            "2025-12-02T23:23:49.105979+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:49.106785+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:49.107749+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:23:49.592855+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:49.594302+0000 | compress | METRIC - error 5126.85\n",
            "2025-12-02T23:23:49.595361+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:49.596084+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:49.597066+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:23:52.292577+0000 | compress | METRIC - time 2.69s\n",
            "2025-12-02T23:23:52.295598+0000 | compress | METRIC - error 236.60\n",
            "2025-12-02T23:23:52.296318+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:52.297307+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(21/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 118.29it/s]\n",
            "(22/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 52.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:55.857061+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:23:56.343467+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:23:56.344798+0000 | compress | METRIC - error 1525.14\n",
            "2025-12-02T23:23:56.345865+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:56.346651+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:23:56.347793+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:23:56.809234+0000 | compress | METRIC - time 0.46s\n",
            "2025-12-02T23:23:56.810492+0000 | compress | METRIC - error 203.87\n",
            "2025-12-02T23:23:56.811586+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:56.812572+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:56.813587+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:23:57.303102+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:23:57.304422+0000 | compress | METRIC - error 629.18\n",
            "2025-12-02T23:23:57.305547+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:57.306297+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:23:57.307536+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:23:57.803736+0000 | compress | METRIC - time 0.50s\n",
            "2025-12-02T23:23:57.805094+0000 | compress | METRIC - error 108.58\n",
            "2025-12-02T23:23:57.805813+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:57.806476+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:23:57.807502+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:23:58.305378+0000 | compress | METRIC - time 0.50s\n",
            "2025-12-02T23:23:58.306597+0000 | compress | METRIC - error 6832.05\n",
            "2025-12-02T23:23:58.307424+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:58.308188+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:58.309390+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:23:58.810397+0000 | compress | METRIC - time 0.50s\n",
            "2025-12-02T23:23:58.811636+0000 | compress | METRIC - error 6529.15\n",
            "2025-12-02T23:23:58.812417+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:23:58.813001+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:23:58.814097+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:24:01.487026+0000 | compress | METRIC - time 2.67s\n",
            "2025-12-02T23:24:01.490115+0000 | compress | METRIC - error 8227.60\n",
            "2025-12-02T23:24:01.490839+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:24:01.491751+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(22/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 115.69it/s]\n",
            "(23/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 51.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:24:05.077065+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:24:05.555262+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:24:05.556625+0000 | compress | METRIC - error 1342.50\n",
            "2025-12-02T23:24:05.557319+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:24:05.557850+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:24:05.559005+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:24:06.012674+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:24:06.013920+0000 | compress | METRIC - error 178.34\n",
            "2025-12-02T23:24:06.014859+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:24:06.015740+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:24:06.016848+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:24:06.463785+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:24:06.465004+0000 | compress | METRIC - error 511.73\n",
            "2025-12-02T23:24:06.466010+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:24:06.466945+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:24:06.467916+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:24:06.920367+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:24:06.921988+0000 | compress | METRIC - error 44.22\n",
            "2025-12-02T23:24:06.922975+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:24:06.923620+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:24:06.924658+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:24:07.401471+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:24:07.403300+0000 | compress | METRIC - error 4374.85\n",
            "2025-12-02T23:24:07.404166+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:24:07.404963+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:24:07.406022+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:24:07.919627+0000 | compress | METRIC - time 0.51s\n",
            "2025-12-02T23:24:07.921085+0000 | compress | METRIC - error 4622.24\n",
            "2025-12-02T23:24:07.921841+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:24:07.922710+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:24:07.923722+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:24:10.631370+0000 | compress | METRIC - time 2.71s\n",
            "2025-12-02T23:24:10.634461+0000 | compress | METRIC - error 326.84\n",
            "2025-12-02T23:24:10.635185+0000 | compress | METRIC - GPU 0 | usage: 11.65% | total memory: 16 GB\n",
            "2025-12-02T23:24:10.635982+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(23/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 119.57it/s]\n",
            "(24/25): Calibrating: 100%|██████████| 128/128 [00:02<00:00, 53.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:24:14.138116+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:24:14.615246+0000 | compress | METRIC - time 0.48s\n",
            "2025-12-02T23:24:14.616455+0000 | compress | METRIC - error 1659.19\n",
            "2025-12-02T23:24:14.617262+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:24:14.617792+0000 | compress | METRIC - Compressed module size: 1.62624 MB\n",
            "2025-12-02T23:24:14.619030+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.k_proj using 128 samples\n",
            "2025-12-02T23:24:15.073761+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:24:15.075093+0000 | compress | METRIC - error 213.45\n",
            "2025-12-02T23:24:15.075993+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:24:15.076886+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:24:15.077853+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.v_proj using 128 samples\n",
            "2025-12-02T23:24:15.527029+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:24:15.528388+0000 | compress | METRIC - error 431.84\n",
            "2025-12-02T23:24:15.529105+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:24:15.530040+0000 | compress | METRIC - Compressed module size: 0.23232 MB\n",
            "2025-12-02T23:24:15.531015+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.o_proj using 128 samples\n",
            "2025-12-02T23:24:15.986173+0000 | compress | METRIC - time 0.45s\n",
            "2025-12-02T23:24:15.987740+0000 | compress | METRIC - error 200.05\n",
            "2025-12-02T23:24:15.988780+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:24:15.989631+0000 | compress | METRIC - Compressed module size: 1.624448 MB\n",
            "2025-12-02T23:24:15.990753+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.gate_proj using 128 samples\n",
            "2025-12-02T23:24:16.464562+0000 | compress | METRIC - time 0.47s\n",
            "2025-12-02T23:24:16.465966+0000 | compress | METRIC - error 5915.20\n",
            "2025-12-02T23:24:16.466843+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:24:16.467700+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:24:16.468684+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.up_proj using 128 samples\n",
            "2025-12-02T23:24:16.954521+0000 | compress | METRIC - time 0.49s\n",
            "2025-12-02T23:24:16.955714+0000 | compress | METRIC - error 5712.58\n",
            "2025-12-02T23:24:16.956546+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:24:16.957182+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n",
            "2025-12-02T23:24:16.958255+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.down_proj using 128 samples\n",
            "2025-12-02T23:24:19.667647+0000 | compress | METRIC - time 2.71s\n",
            "2025-12-02T23:24:19.670667+0000 | compress | METRIC - error 1211.31\n",
            "2025-12-02T23:24:19.671559+0000 | compress | METRIC - GPU 0 | usage: 11.67% | total memory: 16 GB\n",
            "2025-12-02T23:24:19.672230+0000 | compress | METRIC - Compressed module size: 8.818432 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(24/25): Propagating: 100%|██████████| 128/128 [00:01<00:00, 118.13it/s]\n",
            "(25/25): Calibrating: 100%|██████████| 128/128 [00:08<00:00, 15.54it/s]\n",
            "(25/25): Propagating: 100%|██████████| 128/128 [00:08<00:00, 15.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02T23:24:37.702307+0000 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n",
            "2025-12-02T23:24:37.742155+0000 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Compressing model: 168it [00:01, 149.14it/s]\n",
            "Compressing model: 168it [00:00, 1172.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating 200 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:21<00:00,  9.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTQ (Standard) -> Acc: 27.00%, Flip: 39.50%\n",
            "Surgery: Replacing 8 Sensitive Layers with FP16...\n",
            "Surgery Complete: 8 layers restored.\n",
            "Evaluating 200 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:20<00:00,  9.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KLD-GPTQ() -> Acc: 24.50%, Flip: 44.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8164"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Final Summary Table ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"{'Method':<25} | {'Acc':<10} | {'Flip Rate':<10}\")\n",
        "print(\"-\" * 60)\n",
        "order = [\n",
        "    \"FP16 Baseline\",\n",
        "    \"LLM.int8()\", \"KLD-LLM.int8()\",\n",
        "    \"NF4 (Standard)\", \"KLD-NF4()\",\n",
        "    \"AWQ (Standard)\", \"KLD-AWQ()\",\n",
        "    \"GPTQ (Standard)\", \"KLD-GPTQ()\"\n",
        "]\n",
        "for m in order:\n",
        "    if m in results:\n",
        "        v = results[m]\n",
        "        print(f\"{m:<25} | {v['Acc']:<10.2%} | {v['Flip']:<10.2%}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZUdo4ZsSc8u",
        "outputId": "e50e860a-05f3-4699-f7ad-58842a090205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Method                    | Acc        | Flip Rate \n",
            "------------------------------------------------------------\n",
            "LLM.int8()                | 26.00%     | 19.00%    \n",
            "KLD-LLM.int8()            | 25.00%     | 15.50%    \n",
            "NF4 (Standard)            | 26.50%     | 63.00%    \n",
            "KLD-NF4()                 | 28.00%     | 43.00%    \n",
            "AWQ (Standard)            | 29.50%     | 79.00%    \n",
            "KLD-AWQ()                 | 20.50%     | 42.00%    \n",
            "GPTQ (Standard)           | 27.00%     | 39.50%    \n",
            "KLD-GPTQ()                | 24.50%     | 44.00%    \n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "\n",
        "# --- 8. Visualization of Accuracy vs. Flip Rate ---\n",
        "\n",
        "print(\"Generating Visualization...\")\n",
        "\n",
        "# Add FP16 Baseline to results for plotting\n",
        "# `base_acc` is available from earlier execution in cell VMgnsLeIW4JT\n",
        "if 'FP16 Baseline' not in results:\n",
        "    results['FP16 Baseline'] = {'Acc': base_acc, 'Flip': 0.0}\n",
        "\n",
        "# Extract data from the 'results' dictionary\n",
        "# Ensure 'FP16 Baseline' is included in the order for the plot if desired\n",
        "methods = list(results.keys())\n",
        "accuracies = [results[m]['Acc'] for m in methods]\n",
        "flip_rates = [results[m]['Flip'] for m in methods]\n",
        "\n",
        "# Create the Scatter Plot\n",
        "plt.figure(figsize=(10, 7))\n",
        "# Swapping accuracies and flip_rates for x and y axes\n",
        "plt.scatter(flip_rates, accuracies, s=150, c='royalblue', edgecolors='black', alpha=0.7, zorder=2)\n",
        "\n",
        "# Annotate points with method names\n",
        "for i, method in enumerate(methods):\n",
        "    # Offset labels slightly to avoid overlap\n",
        "    offset_y = 0.005 if i % 2 == 0 else -0.005\n",
        "    plt.annotate(\n",
        "        method,\n",
        "        (flip_rates[i], accuracies[i]), # Swapped for annotation as well\n",
        "        xytext=(0, 10),\n",
        "        textcoords='offset points',\n",
        "        ha='center',\n",
        "        fontsize=10,\n",
        "        fontweight='bold'\n",
        "    )\n",
        "\n",
        "# Formatting the Axes\n",
        "plt.title('Accuracy vs. Flip Rate', fontsize=14)\n",
        "plt.xlabel('Flip Rate (Closer to Zero is Better)', fontsize=12) # Swapped xlabel\n",
        "plt.ylabel('Accuracy (Higher is Better)', fontsize=12) # Swapped ylabel\n",
        "\n",
        "# Set percentage formatting for axes (swapped for x and y)\n",
        "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
        "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
        "\n",
        "# Add grid and ideal region marker\n",
        "plt.grid(True, linestyle='--', alpha=0.6, zorder=1)\n",
        "plt.axhline(base_acc, color='green', linestyle=':', label='Baseline Accuracy') # Now horizontal line for accuracy\n",
        "plt.axvline(0, color='grey', linewidth=0.8) # Vertical line for 0 flip rate\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.savefig('accuracy_vs_flips_flipped.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(\"Plot saved as 'accuracy_vs_flips_flipped.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "8QlhP8Z6Dm1X",
        "outputId": "7f46a9df-d08c-4605-b809-9e17f1765738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Visualization...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plot saved as 'accuracy_vs_flips_flipped.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ixlCXlZYSA_d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}